{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AltScore: Data Exploration"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úì Environment setup complete\n",
                        "Analysis started at: 2026-02-15 23:36:15\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "from datetime import datetime\n",
                "import os\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set display options for better output\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.max_rows', 100)\n",
                "pd.set_option('display.float_format', '{:.2f}'.format)\n",
                "\n",
                "# Set visualization style\n",
                "sns.set_style(\"whitegrid\")\n",
                "plt.rcParams['figure.figsize'] = (14, 6)\n",
                "plt.rcParams['font.size'] = 11\n",
                "\n",
                "# Create directories if they don't exist\n",
                "os.makedirs('reports', exist_ok=True)\n",
                "os.makedirs('visualizations', exist_ok=True)\n",
                "\n",
                "print(\"‚úì Environment setup complete\")\n",
                "print(f\"Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Dictionary Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "====================================================================================================\n",
                        "STEP 1: DATA DICTIONARY ANALYSIS\n",
                        "====================================================================================================\n",
                        "\n",
                        "üìä Total columns documented: 219\n",
                        "\n",
                        "üìã Data Dictionary Preview:\n",
                        "    Unnamed: 0                         Table                  Row  \\\n",
                        "0            1  application_{train|test}.csv           SK_ID_CURR   \n",
                        "1            2  application_{train|test}.csv               TARGET   \n",
                        "2            5  application_{train|test}.csv   NAME_CONTRACT_TYPE   \n",
                        "3            6  application_{train|test}.csv          CODE_GENDER   \n",
                        "4            7  application_{train|test}.csv         FLAG_OWN_CAR   \n",
                        "5            8  application_{train|test}.csv      FLAG_OWN_REALTY   \n",
                        "6            9  application_{train|test}.csv         CNT_CHILDREN   \n",
                        "7           10  application_{train|test}.csv     AMT_INCOME_TOTAL   \n",
                        "8           11  application_{train|test}.csv           AMT_CREDIT   \n",
                        "9           12  application_{train|test}.csv          AMT_ANNUITY   \n",
                        "10          13  application_{train|test}.csv      AMT_GOODS_PRICE   \n",
                        "11          14  application_{train|test}.csv      NAME_TYPE_SUITE   \n",
                        "12          15  application_{train|test}.csv     NAME_INCOME_TYPE   \n",
                        "13          16  application_{train|test}.csv  NAME_EDUCATION_TYPE   \n",
                        "14          17  application_{train|test}.csv   NAME_FAMILY_STATUS   \n",
                        "\n",
                        "                                          Description Special  \n",
                        "0                            ID of loan in our sample     NaN  \n",
                        "1   Target variable (1 - client with payment diffi...     NaN  \n",
                        "2         Identification if loan is cash or revolving     NaN  \n",
                        "3                                Gender of the client     NaN  \n",
                        "4                       Flag if the client owns a car     NaN  \n",
                        "5                 Flag if client owns a house or flat     NaN  \n",
                        "6                   Number of children the client has     NaN  \n",
                        "7                                Income of the client     NaN  \n",
                        "8                           Credit amount of the loan     NaN  \n",
                        "9                                        Loan annuity     NaN  \n",
                        "10  For consumer loans it is the price of the good...     NaN  \n",
                        "11  Who was accompanying client when he was applyi...     NaN  \n",
                        "12  Clients income type (businessman, working, mat...     NaN  \n",
                        "13     Level of highest education the client achieved     NaN  \n",
                        "14                        Family status of the client     NaN  \n",
                        "\n",
                        "üìë Columns by Table:\n",
                        "Table\n",
                        "application_{train|test}.csv    122\n",
                        "previous_application.csv         38\n",
                        "credit_card_balance.csv          23\n",
                        "bureau.csv                       17\n",
                        "POS_CASH_balance.csv              8\n",
                        "installments_payments.csv         8\n",
                        "bureau_balance.csv                3\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "‚úì Data dictionary saved to reports/column_descriptions.csv\n"
                    ]
                }
            ],
            "source": [
                "print(\"=\"*100)\n",
                "print(\"STEP 1: DATA DICTIONARY ANALYSIS\")\n",
                "print(\"=\"*100)\n",
                "\n",
                "# Read data dictionary\n",
                "col_desc = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\HomeCredit_columns_description.csv\", encoding='latin-1')\n",
                "\n",
                "print(f\"\\nüìä Total columns documented: {len(col_desc)}\")\n",
                "print(f\"\\nüìã Data Dictionary Preview:\")\n",
                "print(col_desc.head(15))\n",
                "\n",
                "# Analyze column distribution by table\n",
                "if 'Table' in col_desc.columns:\n",
                "    print(\"\\nüìë Columns by Table:\")\n",
                "    print(col_desc['Table'].value_counts())\n",
                "\n",
                "# Save for reference\n",
                "col_desc.to_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\reports\\column_descriptions.csv\", index=False)\n",
                "print(\"\\n‚úì Data dictionary saved to reports/column_descriptions.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Main Training Data - Deep Dive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "====================================================================================================\n",
                        "STEP 2: LOADING & PROFILING APPLICATION_TRAIN.CSV\n",
                        "====================================================================================================\n",
                        "\n",
                        "üì¶ Dataset Dimensions:\n",
                        "   ‚Üí Total Applications: 307,511\n",
                        "   ‚Üí Total Features: 122\n",
                        "   ‚Üí Memory Usage: 536.69 MB\n",
                        "\n",
                        "üìã First 5 Applications:\n",
                        "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
                        "0      100002       1         Cash loans           M            N   \n",
                        "1      100003       0         Cash loans           F            N   \n",
                        "2      100004       0    Revolving loans           M            Y   \n",
                        "3      100006       0         Cash loans           F            N   \n",
                        "4      100007       0         Cash loans           M            N   \n",
                        "\n",
                        "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
                        "0               Y             0         202500.00   406597.50     24700.50   \n",
                        "1               N             0         270000.00  1293502.50     35698.50   \n",
                        "2               Y             0          67500.00   135000.00      6750.00   \n",
                        "3               Y             0         135000.00   312682.50     29686.50   \n",
                        "4               Y             0         121500.00   513000.00     21865.50   \n",
                        "\n",
                        "   AMT_GOODS_PRICE NAME_TYPE_SUITE NAME_INCOME_TYPE  \\\n",
                        "0        351000.00   Unaccompanied          Working   \n",
                        "1       1129500.00          Family    State servant   \n",
                        "2        135000.00   Unaccompanied          Working   \n",
                        "3        297000.00   Unaccompanied          Working   \n",
                        "4        513000.00   Unaccompanied          Working   \n",
                        "\n",
                        "             NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  \\\n",
                        "0  Secondary / secondary special  Single / not married  House / apartment   \n",
                        "1               Higher education               Married  House / apartment   \n",
                        "2  Secondary / secondary special  Single / not married  House / apartment   \n",
                        "3  Secondary / secondary special        Civil marriage  House / apartment   \n",
                        "4  Secondary / secondary special  Single / not married  House / apartment   \n",
                        "\n",
                        "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  \\\n",
                        "0                        0.02       -9461           -637           -3648.00   \n",
                        "1                        0.00      -16765          -1188           -1186.00   \n",
                        "2                        0.01      -19046           -225           -4260.00   \n",
                        "3                        0.01      -19005          -3039           -9833.00   \n",
                        "4                        0.03      -19932          -3038           -4311.00   \n",
                        "\n",
                        "   DAYS_ID_PUBLISH  OWN_CAR_AGE  FLAG_MOBIL  FLAG_EMP_PHONE  FLAG_WORK_PHONE  \\\n",
                        "0            -2120          NaN           1               1                0   \n",
                        "1             -291          NaN           1               1                0   \n",
                        "2            -2531        26.00           1               1                1   \n",
                        "3            -2437          NaN           1               1                0   \n",
                        "4            -3458          NaN           1               1                0   \n",
                        "\n",
                        "   FLAG_CONT_MOBILE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  CNT_FAM_MEMBERS  \\\n",
                        "0                 1           1           0        Laborers             1.00   \n",
                        "1                 1           1           0      Core staff             2.00   \n",
                        "2                 1           1           0        Laborers             1.00   \n",
                        "3                 1           0           0        Laborers             2.00   \n",
                        "4                 1           0           0      Core staff             1.00   \n",
                        "\n",
                        "   REGION_RATING_CLIENT  REGION_RATING_CLIENT_W_CITY  \\\n",
                        "0                     2                            2   \n",
                        "1                     1                            1   \n",
                        "2                     2                            2   \n",
                        "3                     2                            2   \n",
                        "4                     2                            2   \n",
                        "\n",
                        "  WEEKDAY_APPR_PROCESS_START  HOUR_APPR_PROCESS_START  \\\n",
                        "0                  WEDNESDAY                       10   \n",
                        "1                     MONDAY                       11   \n",
                        "2                     MONDAY                        9   \n",
                        "3                  WEDNESDAY                       17   \n",
                        "4                   THURSDAY                       11   \n",
                        "\n",
                        "   REG_REGION_NOT_LIVE_REGION  REG_REGION_NOT_WORK_REGION  \\\n",
                        "0                           0                           0   \n",
                        "1                           0                           0   \n",
                        "2                           0                           0   \n",
                        "3                           0                           0   \n",
                        "4                           0                           0   \n",
                        "\n",
                        "   LIVE_REGION_NOT_WORK_REGION  REG_CITY_NOT_LIVE_CITY  \\\n",
                        "0                            0                       0   \n",
                        "1                            0                       0   \n",
                        "2                            0                       0   \n",
                        "3                            0                       0   \n",
                        "4                            0                       0   \n",
                        "\n",
                        "   REG_CITY_NOT_WORK_CITY  LIVE_CITY_NOT_WORK_CITY       ORGANIZATION_TYPE  \\\n",
                        "0                       0                        0  Business Entity Type 3   \n",
                        "1                       0                        0                  School   \n",
                        "2                       0                        0              Government   \n",
                        "3                       0                        0  Business Entity Type 3   \n",
                        "4                       1                        1                Religion   \n",
                        "\n",
                        "   EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  APARTMENTS_AVG  BASEMENTAREA_AVG  \\\n",
                        "0          0.08          0.26          0.14            0.02              0.04   \n",
                        "1          0.31          0.62           NaN            0.10              0.05   \n",
                        "2           NaN          0.56          0.73             NaN               NaN   \n",
                        "3           NaN          0.65           NaN             NaN               NaN   \n",
                        "4           NaN          0.32           NaN             NaN               NaN   \n",
                        "\n",
                        "   YEARS_BEGINEXPLUATATION_AVG  YEARS_BUILD_AVG  COMMONAREA_AVG  \\\n",
                        "0                         0.97             0.62            0.01   \n",
                        "1                         0.99             0.80            0.06   \n",
                        "2                          NaN              NaN             NaN   \n",
                        "3                          NaN              NaN             NaN   \n",
                        "4                          NaN              NaN             NaN   \n",
                        "\n",
                        "   ELEVATORS_AVG  ENTRANCES_AVG  FLOORSMAX_AVG  FLOORSMIN_AVG  LANDAREA_AVG  \\\n",
                        "0           0.00           0.07           0.08           0.12          0.04   \n",
                        "1           0.08           0.03           0.29           0.33          0.01   \n",
                        "2            NaN            NaN            NaN            NaN           NaN   \n",
                        "3            NaN            NaN            NaN            NaN           NaN   \n",
                        "4            NaN            NaN            NaN            NaN           NaN   \n",
                        "\n",
                        "   LIVINGAPARTMENTS_AVG  LIVINGAREA_AVG  NONLIVINGAPARTMENTS_AVG  \\\n",
                        "0                  0.02            0.02                     0.00   \n",
                        "1                  0.08            0.05                     0.00   \n",
                        "2                   NaN             NaN                      NaN   \n",
                        "3                   NaN             NaN                      NaN   \n",
                        "4                   NaN             NaN                      NaN   \n",
                        "\n",
                        "   NONLIVINGAREA_AVG  APARTMENTS_MODE  BASEMENTAREA_MODE  \\\n",
                        "0               0.00             0.03               0.04   \n",
                        "1               0.01             0.09               0.05   \n",
                        "2                NaN              NaN                NaN   \n",
                        "3                NaN              NaN                NaN   \n",
                        "4                NaN              NaN                NaN   \n",
                        "\n",
                        "   YEARS_BEGINEXPLUATATION_MODE  YEARS_BUILD_MODE  COMMONAREA_MODE  \\\n",
                        "0                          0.97              0.63             0.01   \n",
                        "1                          0.99              0.80             0.05   \n",
                        "2                           NaN               NaN              NaN   \n",
                        "3                           NaN               NaN              NaN   \n",
                        "4                           NaN               NaN              NaN   \n",
                        "\n",
                        "   ELEVATORS_MODE  ENTRANCES_MODE  FLOORSMAX_MODE  FLOORSMIN_MODE  \\\n",
                        "0            0.00            0.07            0.08            0.12   \n",
                        "1            0.08            0.03            0.29            0.33   \n",
                        "2             NaN             NaN             NaN             NaN   \n",
                        "3             NaN             NaN             NaN             NaN   \n",
                        "4             NaN             NaN             NaN             NaN   \n",
                        "\n",
                        "   LANDAREA_MODE  LIVINGAPARTMENTS_MODE  LIVINGAREA_MODE  \\\n",
                        "0           0.04                   0.02             0.02   \n",
                        "1           0.01                   0.08             0.06   \n",
                        "2            NaN                    NaN              NaN   \n",
                        "3            NaN                    NaN              NaN   \n",
                        "4            NaN                    NaN              NaN   \n",
                        "\n",
                        "   NONLIVINGAPARTMENTS_MODE  NONLIVINGAREA_MODE  APARTMENTS_MEDI  \\\n",
                        "0                      0.00                0.00             0.03   \n",
                        "1                      0.00                0.00             0.10   \n",
                        "2                       NaN                 NaN              NaN   \n",
                        "3                       NaN                 NaN              NaN   \n",
                        "4                       NaN                 NaN              NaN   \n",
                        "\n",
                        "   BASEMENTAREA_MEDI  YEARS_BEGINEXPLUATATION_MEDI  YEARS_BUILD_MEDI  \\\n",
                        "0               0.04                          0.97              0.62   \n",
                        "1               0.05                          0.99              0.80   \n",
                        "2                NaN                           NaN               NaN   \n",
                        "3                NaN                           NaN               NaN   \n",
                        "4                NaN                           NaN               NaN   \n",
                        "\n",
                        "   COMMONAREA_MEDI  ELEVATORS_MEDI  ENTRANCES_MEDI  FLOORSMAX_MEDI  \\\n",
                        "0             0.01            0.00            0.07            0.08   \n",
                        "1             0.06            0.08            0.03            0.29   \n",
                        "2              NaN             NaN             NaN             NaN   \n",
                        "3              NaN             NaN             NaN             NaN   \n",
                        "4              NaN             NaN             NaN             NaN   \n",
                        "\n",
                        "   FLOORSMIN_MEDI  LANDAREA_MEDI  LIVINGAPARTMENTS_MEDI  LIVINGAREA_MEDI  \\\n",
                        "0            0.12           0.04                   0.02             0.02   \n",
                        "1            0.33           0.01                   0.08             0.06   \n",
                        "2             NaN            NaN                    NaN              NaN   \n",
                        "3             NaN            NaN                    NaN              NaN   \n",
                        "4             NaN            NaN                    NaN              NaN   \n",
                        "\n",
                        "   NONLIVINGAPARTMENTS_MEDI  NONLIVINGAREA_MEDI FONDKAPREMONT_MODE  \\\n",
                        "0                      0.00                0.00   reg oper account   \n",
                        "1                      0.00                0.01   reg oper account   \n",
                        "2                       NaN                 NaN                NaN   \n",
                        "3                       NaN                 NaN                NaN   \n",
                        "4                       NaN                 NaN                NaN   \n",
                        "\n",
                        "   HOUSETYPE_MODE  TOTALAREA_MODE WALLSMATERIAL_MODE EMERGENCYSTATE_MODE  \\\n",
                        "0  block of flats            0.01       Stone, brick                  No   \n",
                        "1  block of flats            0.07              Block                  No   \n",
                        "2             NaN             NaN                NaN                 NaN   \n",
                        "3             NaN             NaN                NaN                 NaN   \n",
                        "4             NaN             NaN                NaN                 NaN   \n",
                        "\n",
                        "   OBS_30_CNT_SOCIAL_CIRCLE  DEF_30_CNT_SOCIAL_CIRCLE  \\\n",
                        "0                      2.00                      2.00   \n",
                        "1                      1.00                      0.00   \n",
                        "2                      0.00                      0.00   \n",
                        "3                      2.00                      0.00   \n",
                        "4                      0.00                      0.00   \n",
                        "\n",
                        "   OBS_60_CNT_SOCIAL_CIRCLE  DEF_60_CNT_SOCIAL_CIRCLE  DAYS_LAST_PHONE_CHANGE  \\\n",
                        "0                      2.00                      2.00                -1134.00   \n",
                        "1                      1.00                      0.00                 -828.00   \n",
                        "2                      0.00                      0.00                 -815.00   \n",
                        "3                      2.00                      0.00                 -617.00   \n",
                        "4                      0.00                      0.00                -1106.00   \n",
                        "\n",
                        "   FLAG_DOCUMENT_2  FLAG_DOCUMENT_3  FLAG_DOCUMENT_4  FLAG_DOCUMENT_5  \\\n",
                        "0                0                1                0                0   \n",
                        "1                0                1                0                0   \n",
                        "2                0                0                0                0   \n",
                        "3                0                1                0                0   \n",
                        "4                0                0                0                0   \n",
                        "\n",
                        "   FLAG_DOCUMENT_6  FLAG_DOCUMENT_7  FLAG_DOCUMENT_8  FLAG_DOCUMENT_9  \\\n",
                        "0                0                0                0                0   \n",
                        "1                0                0                0                0   \n",
                        "2                0                0                0                0   \n",
                        "3                0                0                0                0   \n",
                        "4                0                0                1                0   \n",
                        "\n",
                        "   FLAG_DOCUMENT_10  FLAG_DOCUMENT_11  FLAG_DOCUMENT_12  FLAG_DOCUMENT_13  \\\n",
                        "0                 0                 0                 0                 0   \n",
                        "1                 0                 0                 0                 0   \n",
                        "2                 0                 0                 0                 0   \n",
                        "3                 0                 0                 0                 0   \n",
                        "4                 0                 0                 0                 0   \n",
                        "\n",
                        "   FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  \\\n",
                        "0                 0                 0                 0                 0   \n",
                        "1                 0                 0                 0                 0   \n",
                        "2                 0                 0                 0                 0   \n",
                        "3                 0                 0                 0                 0   \n",
                        "4                 0                 0                 0                 0   \n",
                        "\n",
                        "   FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  \\\n",
                        "0                 0                 0                 0                 0   \n",
                        "1                 0                 0                 0                 0   \n",
                        "2                 0                 0                 0                 0   \n",
                        "3                 0                 0                 0                 0   \n",
                        "4                 0                 0                 0                 0   \n",
                        "\n",
                        "   AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
                        "0                        0.00                       0.00   \n",
                        "1                        0.00                       0.00   \n",
                        "2                        0.00                       0.00   \n",
                        "3                         NaN                        NaN   \n",
                        "4                        0.00                       0.00   \n",
                        "\n",
                        "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
                        "0                        0.00                       0.00   \n",
                        "1                        0.00                       0.00   \n",
                        "2                        0.00                       0.00   \n",
                        "3                         NaN                        NaN   \n",
                        "4                        0.00                       0.00   \n",
                        "\n",
                        "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
                        "0                       0.00                        1.00  \n",
                        "1                       0.00                        0.00  \n",
                        "2                       0.00                        0.00  \n",
                        "3                        NaN                         NaN  \n",
                        "4                       0.00                        0.00  \n",
                        "\n",
                        "üìù All Feature Names (122 total):\n",
                        "     1. SK_ID_CURR\n",
                        "     2. TARGET\n",
                        "     3. NAME_CONTRACT_TYPE\n",
                        "     4. CODE_GENDER\n",
                        "     5. FLAG_OWN_CAR\n",
                        "     6. FLAG_OWN_REALTY\n",
                        "     7. CNT_CHILDREN\n",
                        "     8. AMT_INCOME_TOTAL\n",
                        "     9. AMT_CREDIT\n",
                        "    10. AMT_ANNUITY\n",
                        "    11. AMT_GOODS_PRICE\n",
                        "    12. NAME_TYPE_SUITE\n",
                        "    13. NAME_INCOME_TYPE\n",
                        "    14. NAME_EDUCATION_TYPE\n",
                        "    15. NAME_FAMILY_STATUS\n",
                        "    16. NAME_HOUSING_TYPE\n",
                        "    17. REGION_POPULATION_RELATIVE\n",
                        "    18. DAYS_BIRTH\n",
                        "    19. DAYS_EMPLOYED\n",
                        "    20. DAYS_REGISTRATION\n",
                        "\n",
                        "    21. DAYS_ID_PUBLISH\n",
                        "    22. OWN_CAR_AGE\n",
                        "    23. FLAG_MOBIL\n",
                        "    24. FLAG_EMP_PHONE\n",
                        "    25. FLAG_WORK_PHONE\n",
                        "    26. FLAG_CONT_MOBILE\n",
                        "    27. FLAG_PHONE\n",
                        "    28. FLAG_EMAIL\n",
                        "    29. OCCUPATION_TYPE\n",
                        "    30. CNT_FAM_MEMBERS\n",
                        "    31. REGION_RATING_CLIENT\n",
                        "    32. REGION_RATING_CLIENT_W_CITY\n",
                        "    33. WEEKDAY_APPR_PROCESS_START\n",
                        "    34. HOUR_APPR_PROCESS_START\n",
                        "    35. REG_REGION_NOT_LIVE_REGION\n",
                        "    36. REG_REGION_NOT_WORK_REGION\n",
                        "    37. LIVE_REGION_NOT_WORK_REGION\n",
                        "    38. REG_CITY_NOT_LIVE_CITY\n",
                        "    39. REG_CITY_NOT_WORK_CITY\n",
                        "    40. LIVE_CITY_NOT_WORK_CITY\n",
                        "\n",
                        "    41. ORGANIZATION_TYPE\n",
                        "    42. EXT_SOURCE_1\n",
                        "    43. EXT_SOURCE_2\n",
                        "    44. EXT_SOURCE_3\n",
                        "    45. APARTMENTS_AVG\n",
                        "    46. BASEMENTAREA_AVG\n",
                        "    47. YEARS_BEGINEXPLUATATION_AVG\n",
                        "    48. YEARS_BUILD_AVG\n",
                        "    49. COMMONAREA_AVG\n",
                        "    50. ELEVATORS_AVG\n",
                        "    51. ENTRANCES_AVG\n",
                        "    52. FLOORSMAX_AVG\n",
                        "    53. FLOORSMIN_AVG\n",
                        "    54. LANDAREA_AVG\n",
                        "    55. LIVINGAPARTMENTS_AVG\n",
                        "    56. LIVINGAREA_AVG\n",
                        "    57. NONLIVINGAPARTMENTS_AVG\n",
                        "    58. NONLIVINGAREA_AVG\n",
                        "    59. APARTMENTS_MODE\n",
                        "    60. BASEMENTAREA_MODE\n",
                        "\n",
                        "    61. YEARS_BEGINEXPLUATATION_MODE\n",
                        "    62. YEARS_BUILD_MODE\n",
                        "    63. COMMONAREA_MODE\n",
                        "    64. ELEVATORS_MODE\n",
                        "    65. ENTRANCES_MODE\n",
                        "    66. FLOORSMAX_MODE\n",
                        "    67. FLOORSMIN_MODE\n",
                        "    68. LANDAREA_MODE\n",
                        "    69. LIVINGAPARTMENTS_MODE\n",
                        "    70. LIVINGAREA_MODE\n",
                        "    71. NONLIVINGAPARTMENTS_MODE\n",
                        "    72. NONLIVINGAREA_MODE\n",
                        "    73. APARTMENTS_MEDI\n",
                        "    74. BASEMENTAREA_MEDI\n",
                        "    75. YEARS_BEGINEXPLUATATION_MEDI\n",
                        "    76. YEARS_BUILD_MEDI\n",
                        "    77. COMMONAREA_MEDI\n",
                        "    78. ELEVATORS_MEDI\n",
                        "    79. ENTRANCES_MEDI\n",
                        "    80. FLOORSMAX_MEDI\n",
                        "\n",
                        "    81. FLOORSMIN_MEDI\n",
                        "    82. LANDAREA_MEDI\n",
                        "    83. LIVINGAPARTMENTS_MEDI\n",
                        "    84. LIVINGAREA_MEDI\n",
                        "    85. NONLIVINGAPARTMENTS_MEDI\n",
                        "    86. NONLIVINGAREA_MEDI\n",
                        "    87. FONDKAPREMONT_MODE\n",
                        "    88. HOUSETYPE_MODE\n",
                        "    89. TOTALAREA_MODE\n",
                        "    90. WALLSMATERIAL_MODE\n",
                        "    91. EMERGENCYSTATE_MODE\n",
                        "    92. OBS_30_CNT_SOCIAL_CIRCLE\n",
                        "    93. DEF_30_CNT_SOCIAL_CIRCLE\n",
                        "    94. OBS_60_CNT_SOCIAL_CIRCLE\n",
                        "    95. DEF_60_CNT_SOCIAL_CIRCLE\n",
                        "    96. DAYS_LAST_PHONE_CHANGE\n",
                        "    97. FLAG_DOCUMENT_2\n",
                        "    98. FLAG_DOCUMENT_3\n",
                        "    99. FLAG_DOCUMENT_4\n",
                        "   100. FLAG_DOCUMENT_5\n",
                        "\n",
                        "   101. FLAG_DOCUMENT_6\n",
                        "   102. FLAG_DOCUMENT_7\n",
                        "   103. FLAG_DOCUMENT_8\n",
                        "   104. FLAG_DOCUMENT_9\n",
                        "   105. FLAG_DOCUMENT_10\n",
                        "   106. FLAG_DOCUMENT_11\n",
                        "   107. FLAG_DOCUMENT_12\n",
                        "   108. FLAG_DOCUMENT_13\n",
                        "   109. FLAG_DOCUMENT_14\n",
                        "   110. FLAG_DOCUMENT_15\n",
                        "   111. FLAG_DOCUMENT_16\n",
                        "   112. FLAG_DOCUMENT_17\n",
                        "   113. FLAG_DOCUMENT_18\n",
                        "   114. FLAG_DOCUMENT_19\n",
                        "   115. FLAG_DOCUMENT_20\n",
                        "   116. FLAG_DOCUMENT_21\n",
                        "   117. AMT_REQ_CREDIT_BUREAU_HOUR\n",
                        "   118. AMT_REQ_CREDIT_BUREAU_DAY\n",
                        "   119. AMT_REQ_CREDIT_BUREAU_WEEK\n",
                        "   120. AMT_REQ_CREDIT_BUREAU_MON\n",
                        "\n",
                        "   121. AMT_REQ_CREDIT_BUREAU_QRT\n",
                        "   122. AMT_REQ_CREDIT_BUREAU_YEAR\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*100)\n",
                "print(\"STEP 2: LOADING & PROFILING APPLICATION_TRAIN.CSV\")\n",
                "print(\"=\"*100)\n",
                "\n",
                "# Load main training data\n",
                "train = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\application_train.csv\")\n",
                "\n",
                "print(f\"\\nüì¶ Dataset Dimensions:\")\n",
                "print(f\"   ‚Üí Total Applications: {train.shape[0]:,}\")\n",
                "print(f\"   ‚Üí Total Features: {train.shape[1]}\")\n",
                "print(f\"   ‚Üí Memory Usage: {train.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
                "\n",
                "# Display first few rows\n",
                "print(\"\\nüìã First 5 Applications:\")\n",
                "print(train.head())\n",
                "\n",
                "# Column names\n",
                "print(f\"\\nüìù All Feature Names ({len(train.columns)} total):\")\n",
                "for i, col in enumerate(train.columns, 1):\n",
                "    print(f\"   {i:3d}. {col}\")\n",
                "    if i % 20 == 0 and i < len(train.columns):\n",
                "        print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Target Variable - Comprehensive Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "====================================================================================================\n",
                        "STEP 3: TARGET VARIABLE ANALYSIS\n",
                        "====================================================================================================\n",
                        "\n",
                        "üéØ Target Distribution:\n",
                        "   ‚Üí Repaid (0):    282,686 (91.93%)\n",
                        "   ‚Üí Defaulted (1): 24,825 (8.07%)\n",
                        "\n",
                        "üìä Class Imbalance Ratio: 1:11 (Default:Repaid)\n",
                        "\n",
                        "üìà Target Statistics:\n",
                        "   ‚Üí Mean (avg default rate): 0.0807\n",
                        "   ‚Üí Std Dev: 0.2724\n",
                        "   ‚Üí Variance: 0.0742\n",
                        "\n",
                        "‚úì Target analysis saved to reports/target_distribution.csv\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*100)\n",
                "print(\"STEP 3: TARGET VARIABLE ANALYSIS\")\n",
                "print(\"=\"*100)\n",
                "\n",
                "# Target distribution\n",
                "target_dist = train['TARGET'].value_counts().sort_index()\n",
                "default_rate = (target_dist[1] / len(train)) * 100\n",
                "repayment_rate = (target_dist[0] / len(train)) * 100\n",
                "\n",
                "print(\"\\nüéØ Target Distribution:\")\n",
                "print(f\"   ‚Üí Repaid (0):    {target_dist[0]:,} ({repayment_rate:.2f}%)\")\n",
                "print(f\"   ‚Üí Defaulted (1): {target_dist[1]:,} ({default_rate:.2f}%)\")\n",
                "print(f\"\\nüìä Class Imbalance Ratio: 1:{int(target_dist[0]/target_dist[1])} (Default:Repaid)\")\n",
                "\n",
                "# Statistical summary\n",
                "print(\"\\nüìà Target Statistics:\")\n",
                "print(f\"   ‚Üí Mean (avg default rate): {train['TARGET'].mean():.4f}\")\n",
                "print(f\"   ‚Üí Std Dev: {train['TARGET'].std():.4f}\")\n",
                "print(f\"   ‚Üí Variance: {train['TARGET'].var():.4f}\")\n",
                "\n",
                "# Save detailed target analysis\n",
                "target_stats = pd.DataFrame({\n",
                "    'Category': ['Repaid (0)', 'Defaulted (1)'],\n",
                "    'Count': target_dist.values,\n",
                "    'Percentage': [repayment_rate, default_rate],\n",
                "    'Proportion': [target_dist[0]/len(train), target_dist[1]/len(train)]\n",
                "})\n",
                "target_stats.to_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\reports\\target_distribution.csv\", index=False)\n",
                "\n",
                "print(\"\\n‚úì Target analysis saved to reports/target_distribution.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Data Types & Structure Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "====================================================================================================\n",
                        "STEP 4: DATA TYPES & STRUCTURE ANALYSIS\n",
                        "====================================================================================================\n",
                        "\n",
                        "üîç Data Type Distribution:\n",
                        "   ‚Üí float64        :  65 columns (53.3%)\n",
                        "   ‚Üí int64          :  41 columns (33.6%)\n",
                        "   ‚Üí object         :  16 columns (13.1%)\n",
                        "\n",
                        "üìä Feature Categories:\n",
                        "   ‚Üí Numeric features: 106\n",
                        "   ‚Üí Categorical features: 16\n",
                        "\n",
                        "üìã Categorical Features:\n",
                        "                   Feature  Unique_Values                                                      Sample_Values\n",
                        "        NAME_CONTRACT_TYPE              2                                        Cash loans, Revolving loans\n",
                        "               CODE_GENDER              3                                                          M, F, XNA\n",
                        "              FLAG_OWN_CAR              2                                                               N, Y\n",
                        "           FLAG_OWN_REALTY              2                                                               Y, N\n",
                        "           NAME_TYPE_SUITE              7                             Unaccompanied, Family, Spouse, partner\n",
                        "          NAME_INCOME_TYPE              8                       Working, State servant, Commercial associate\n",
                        "       NAME_EDUCATION_TYPE              5 Secondary / secondary special, Higher education, Incomplete higher\n",
                        "        NAME_FAMILY_STATUS              6                      Single / not married, Married, Civil marriage\n",
                        "         NAME_HOUSING_TYPE              6                  House / apartment, Rented apartment, With parents\n",
                        "           OCCUPATION_TYPE             18                                  Laborers, Core staff, Accountants\n",
                        "WEEKDAY_APPR_PROCESS_START              7                                        WEDNESDAY, MONDAY, THURSDAY\n",
                        "         ORGANIZATION_TYPE             58                         Business Entity Type 3, School, Government\n",
                        "        FONDKAPREMONT_MODE              4          reg oper account, org spec account, reg oper spec account\n",
                        "            HOUSETYPE_MODE              3                   block of flats, terraced house, specific housing\n",
                        "        WALLSMATERIAL_MODE              7                                         Stone, brick, Block, Panel\n",
                        "       EMERGENCYSTATE_MODE              2                                                            No, Yes\n",
                        "\n",
                        "üìä Numeric Features - Quick Stats:\n",
                        "                               count      mean       std       min       25%  \\\n",
                        "SK_ID_CURR                 307511.00 278180.52 102790.18 100002.00 189145.50   \n",
                        "TARGET                     307511.00      0.08      0.27      0.00      0.00   \n",
                        "CNT_CHILDREN               307511.00      0.42      0.72      0.00      0.00   \n",
                        "AMT_INCOME_TOTAL           307511.00 168797.92 237123.15  25650.00 112500.00   \n",
                        "AMT_CREDIT                 307511.00 599026.00 402490.78  45000.00 270000.00   \n",
                        "AMT_ANNUITY                307499.00  27108.57  14493.74   1615.50  16524.00   \n",
                        "AMT_GOODS_PRICE            307233.00 538396.21 369446.46  40500.00 238500.00   \n",
                        "REGION_POPULATION_RELATIVE 307511.00      0.02      0.01      0.00      0.01   \n",
                        "DAYS_BIRTH                 307511.00 -16037.00   4363.99 -25229.00 -19682.00   \n",
                        "DAYS_EMPLOYED              307511.00  63815.05 141275.77 -17912.00  -2760.00   \n",
                        "\n",
                        "                                 50%       75%          max  missing_%  \n",
                        "SK_ID_CURR                 278202.00 367142.50    456255.00       0.00  \n",
                        "TARGET                          0.00      0.00         1.00       0.00  \n",
                        "CNT_CHILDREN                    0.00      1.00        19.00       0.00  \n",
                        "AMT_INCOME_TOTAL           147150.00 202500.00 117000000.00       0.00  \n",
                        "AMT_CREDIT                 513531.00 808650.00   4050000.00       0.00  \n",
                        "AMT_ANNUITY                 24903.00  34596.00    258025.50       0.00  \n",
                        "AMT_GOODS_PRICE            450000.00 679500.00   4050000.00       0.09  \n",
                        "REGION_POPULATION_RELATIVE      0.02      0.03         0.07       0.00  \n",
                        "DAYS_BIRTH                 -15750.00 -12413.00     -7489.00       0.00  \n",
                        "DAYS_EMPLOYED               -1213.00   -289.00    365243.00       0.00  \n",
                        "\n",
                        "‚úì Data type analysis saved\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*100)\n",
                "print(\"STEP 4: DATA TYPES & STRUCTURE ANALYSIS\")\n",
                "print(\"=\"*100)\n",
                "\n",
                "# Data type distribution\n",
                "dtype_counts = train.dtypes.value_counts()\n",
                "print(\"\\nüîç Data Type Distribution:\")\n",
                "for dtype, count in dtype_counts.items():\n",
                "    print(f\"   ‚Üí {str(dtype):15s}: {count:3d} columns ({count/len(train.columns)*100:.1f}%)\")\n",
                "\n",
                "# Separate columns by type\n",
                "numeric_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
                "categorical_cols = train.select_dtypes(include=['object']).columns.tolist()\n",
                "\n",
                "print(f\"\\nüìä Feature Categories:\")\n",
                "print(f\"   ‚Üí Numeric features: {len(numeric_cols)}\")\n",
                "print(f\"   ‚Üí Categorical features: {len(categorical_cols)}\")\n",
                "\n",
                "# Categorical feature details\n",
                "if categorical_cols:\n",
                "    print(\"\\nüìã Categorical Features:\")\n",
                "    cat_summary = []\n",
                "    for col in categorical_cols:\n",
                "        unique_count = train[col].nunique()\n",
                "        cat_summary.append({\n",
                "            'Feature': col,\n",
                "            'Unique_Values': unique_count,\n",
                "            'Sample_Values': ', '.join(train[col].dropna().unique()[:3].astype(str))\n",
                "        })\n",
                "    \n",
                "    cat_df = pd.DataFrame(cat_summary)\n",
                "    print(cat_df.to_string(index=False))\n",
                "    cat_df.to_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\reports\\categorical_features_summary.csv\", index=False)\n",
                "\n",
                "# Numeric feature statistics\n",
                "print(\"\\nüìä Numeric Features - Quick Stats:\")\n",
                "numeric_stats = train[numeric_cols].describe().T\n",
                "numeric_stats['missing_%'] = (train[numeric_cols].isnull().sum() / len(train) * 100).values\n",
                "print(numeric_stats.head(10))\n",
                "numeric_stats.to_csv('reports/numeric_features_statistics.csv')\n",
                "\n",
                "print(\"\\n‚úì Data type analysis saved\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Missing Values - Detailed Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "====================================================================================================\n",
                        "STEP 5: COMPREHENSIVE MISSING VALUES ANALYSIS\n",
                        "====================================================================================================\n",
                        "\n",
                        "üîç Missing Value Summary:\n",
                        "   ‚Üí Columns with missing values: 67/122\n",
                        "   ‚Üí Columns with >50% missing: 41\n",
                        "   ‚Üí Columns with >80% missing: 0\n",
                        "   ‚Üí Average missing % per column: 24.40%\n",
                        "\n",
                        "üìä Missing Value Severity Distribution:\n",
                        "Severity\n",
                        "Very High (50-80%)    41\n",
                        "Low (<5%)             10\n",
                        "High (20-50%)          9\n",
                        "Moderate (5-20%)       7\n",
                        "Critical (>80%)        0\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "‚ö†Ô∏è  Top 20 Features with Highest Missing Values:\n",
                        "                 Feature  Missing_Count  Missing_Percentage Data_Type  Non_Missing_Count           Severity\n",
                        "         COMMONAREA_MEDI         214865               69.87   float64              92646 Very High (50-80%)\n",
                        "         COMMONAREA_MODE         214865               69.87   float64              92646 Very High (50-80%)\n",
                        "          COMMONAREA_AVG         214865               69.87   float64              92646 Very High (50-80%)\n",
                        "NONLIVINGAPARTMENTS_MODE         213514               69.43   float64              93997 Very High (50-80%)\n",
                        "NONLIVINGAPARTMENTS_MEDI         213514               69.43   float64              93997 Very High (50-80%)\n",
                        " NONLIVINGAPARTMENTS_AVG         213514               69.43   float64              93997 Very High (50-80%)\n",
                        "      FONDKAPREMONT_MODE         210295               68.39    object              97216 Very High (50-80%)\n",
                        "    LIVINGAPARTMENTS_AVG         210199               68.35   float64              97312 Very High (50-80%)\n",
                        "   LIVINGAPARTMENTS_MEDI         210199               68.35   float64              97312 Very High (50-80%)\n",
                        "   LIVINGAPARTMENTS_MODE         210199               68.35   float64              97312 Very High (50-80%)\n",
                        "          FLOORSMIN_MEDI         208642               67.85   float64              98869 Very High (50-80%)\n",
                        "          FLOORSMIN_MODE         208642               67.85   float64              98869 Very High (50-80%)\n",
                        "           FLOORSMIN_AVG         208642               67.85   float64              98869 Very High (50-80%)\n",
                        "        YEARS_BUILD_MODE         204488               66.50   float64             103023 Very High (50-80%)\n",
                        "        YEARS_BUILD_MEDI         204488               66.50   float64             103023 Very High (50-80%)\n",
                        "         YEARS_BUILD_AVG         204488               66.50   float64             103023 Very High (50-80%)\n",
                        "             OWN_CAR_AGE         202929               65.99   float64             104582 Very High (50-80%)\n",
                        "            LANDAREA_AVG         182590               59.38   float64             124921 Very High (50-80%)\n",
                        "           LANDAREA_MEDI         182590               59.38   float64             124921 Very High (50-80%)\n",
                        "           LANDAREA_MODE         182590               59.38   float64             124921 Very High (50-80%)\n",
                        "\n",
                        "‚úì Missing value analysis saved to reports/missing_values_analysis.csv\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*100)\n",
                "print(\"STEP 5: COMPREHENSIVE MISSING VALUES ANALYSIS\")\n",
                "print(\"=\"*100)\n",
                "\n",
                "# Calculate missing values\n",
                "missing_count = train.isnull().sum()\n",
                "missing_pct = (missing_count / len(train)) * 100\n",
                "\n",
                "# Create detailed missing value report\n",
                "missing_df = pd.DataFrame({\n",
                "    'Feature': train.columns,\n",
                "    'Missing_Count': missing_count.values,\n",
                "    'Missing_Percentage': missing_pct.values,\n",
                "    'Data_Type': train.dtypes.values,\n",
                "    'Non_Missing_Count': len(train) - missing_count.values\n",
                "})\n",
                "\n",
                "# Filter and sort\n",
                "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
                "\n",
                "print(f\"\\nüîç Missing Value Summary:\")\n",
                "print(f\"   ‚Üí Columns with missing values: {len(missing_df)}/{len(train.columns)}\")\n",
                "print(f\"   ‚Üí Columns with >50% missing: {len(missing_df[missing_df['Missing_Percentage'] > 50])}\")\n",
                "print(f\"   ‚Üí Columns with >80% missing: {len(missing_df[missing_df['Missing_Percentage'] > 80])}\")\n",
                "print(f\"   ‚Üí Average missing % per column: {missing_pct.mean():.2f}%\")\n",
                "\n",
                "# Categorize missing value severity\n",
                "missing_df['Severity'] = pd.cut(\n",
                "    missing_df['Missing_Percentage'],\n",
                "    bins=[0, 5, 20, 50, 80, 100],\n",
                "    labels=['Low (<5%)', 'Moderate (5-20%)', 'High (20-50%)', 'Very High (50-80%)', 'Critical (>80%)']\n",
                ")\n",
                "\n",
                "print(\"\\nüìä Missing Value Severity Distribution:\")\n",
                "print(missing_df['Severity'].value_counts())\n",
                "\n",
                "# Top 20 features with missing values\n",
                "print(\"\\n‚ö†Ô∏è  Top 20 Features with Highest Missing Values:\")\n",
                "print(missing_df.head(20).to_string(index=False))\n",
                "\n",
                "# Save detailed report\n",
                "missing_df.to_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\reports\\missing_values_analysis.csv\", index=False)\n",
                "\n",
                "# Create missing value heatmap data for later visualization\n",
                "missing_matrix = train[missing_df.head(30)['Feature'].tolist()].isnull().astype(int)\n",
                "missing_matrix.to_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\reports\\missing_values_matrix.csv\", index=False)\n",
                "\n",
                "print(\"\\n‚úì Missing value analysis saved to reports/missing_values_analysis.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Load All Supplementary Datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "====================================================================================================\n",
                        "STEP 6: LOADING ALL SUPPLEMENTARY DATASETS\n",
                        "====================================================================================================\n",
                        "\n",
                        "üì• Loading datasets...\n",
                        "   [1/6] Loading bureau.csv...\n",
                        "   [2/6] Loading bureau_balance.csv...\n",
                        "   [3/6] Loading previous_application.csv...\n",
                        "   [4/6] Loading POS_CASH_balance.csv...\n",
                        "   [5/6] Loading credit_card_balance.csv...\n",
                        "   [6/6] Loading installments_payments.csv...\n",
                        "\n",
                        "‚úì All datasets loaded successfully\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*100)\n",
                "print(\"STEP 6: LOADING ALL SUPPLEMENTARY DATASETS\")\n",
                "print(\"=\"*100)\n",
                "\n",
                "print(\"\\nüì• Loading datasets...\")\n",
                "\n",
                "# Load all supplementary files with progress indication\n",
                "datasets = {}\n",
                "\n",
                "print(\"   [1/6] Loading bureau.csv...\")\n",
                "datasets['bureau'] = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\bureau.csv\")\n",
                "\n",
                "print(\"   [2/6] Loading bureau_balance.csv...\")\n",
                "datasets['bureau_balance'] = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\bureau_balance.csv\")\n",
                "\n",
                "print(\"   [3/6] Loading previous_application.csv...\")\n",
                "datasets['previous_application'] = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\previous_application.csv\")\n",
                "\n",
                "print(\"   [4/6] Loading POS_CASH_balance.csv...\")\n",
                "datasets['POS_CASH_balance'] = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\POS_CASH_balance.csv\")\n",
                "\n",
                "print(\"   [5/6] Loading credit_card_balance.csv...\")\n",
                "datasets['credit_card_balance'] = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\credit_card_balance.csv\")\n",
                "\n",
                "print(\"   [6/6] Loading installments_payments.csv...\")\n",
                "datasets['installments_payments'] = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\installments_payments.csv\")\n",
                "\n",
                "print(\"\\n‚úì All datasets loaded successfully\")\n",
                "\n",
                "# Store for easy access\n",
                "bureau = datasets['bureau']\n",
                "bureau_balance = datasets['bureau_balance']\n",
                "previous_app = datasets['previous_application']\n",
                "pos_cash = datasets['POS_CASH_balance']\n",
                "credit_card = datasets['credit_card_balance']\n",
                "installments = datasets['installments_payments']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Dataset Summary & Profiling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "====================================================================================================\n",
                        "STEP 7: COMPREHENSIVE DATASET PROFILING\n",
                        "====================================================================================================\n",
                        "\n",
                        "üìä Complete Dataset Overview:\n",
                        "              Dataset     Rows  Columns  Memory_MB              Primary_Key\n",
                        "    application_train   307511      122     536.69               SK_ID_CURR\n",
                        "               bureau  1716428       17     512.11 SK_ID_CURR, SK_ID_BUREAU\n",
                        "       bureau_balance 27299925        3    1926.61             SK_ID_BUREAU\n",
                        " previous_application  1670214       37    1900.63   SK_ID_CURR, SK_ID_PREV\n",
                        "     POS_CASH_balance 10001358        8    1137.25               SK_ID_PREV\n",
                        "  credit_card_balance  3840312       23     875.69               SK_ID_PREV\n",
                        "installments_payments 13605401        8     830.41               SK_ID_PREV\n",
                        "\n",
                        "üìà Aggregate Statistics:\n",
                        "   ‚Üí Total Records Across All Tables: 58,441,149\n",
                        "   ‚Üí Total Features: 218\n",
                        "   ‚Üí Total Memory Usage: 7719.39 MB\n",
                        "\n",
                        "‚úì Dataset summary saved to reports/datasets_summary.csv\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*100)\n",
                "print(\"STEP 7: COMPREHENSIVE DATASET PROFILING\")\n",
                "print(\"=\"*100)\n",
                "\n",
                "# Create comprehensive dataset summary\n",
                "datasets_info = pd.DataFrame({\n",
                "    'Dataset': [\n",
                "        'application_train',\n",
                "        'bureau',\n",
                "        'bureau_balance',\n",
                "        'previous_application',\n",
                "        'POS_CASH_balance',\n",
                "        'credit_card_balance',\n",
                "        'installments_payments'\n",
                "    ],\n",
                "    'Rows': [\n",
                "        len(train),\n",
                "        len(bureau),\n",
                "        len(bureau_balance),\n",
                "        len(previous_app),\n",
                "        len(pos_cash),\n",
                "        len(credit_card),\n",
                "        len(installments)\n",
                "    ],\n",
                "    'Columns': [\n",
                "        train.shape[1],\n",
                "        bureau.shape[1],\n",
                "        bureau_balance.shape[1],\n",
                "        previous_app.shape[1],\n",
                "        pos_cash.shape[1],\n",
                "        credit_card.shape[1],\n",
                "        installments.shape[1]\n",
                "    ]\n",
                "})\n",
                "\n",
                "# Add memory usage\n",
                "datasets_info['Memory_MB'] = [\n",
                "    train.memory_usage(deep=True).sum() / 1024**2,\n",
                "    bureau.memory_usage(deep=True).sum() / 1024**2,\n",
                "    bureau_balance.memory_usage(deep=True).sum() / 1024**2,\n",
                "    previous_app.memory_usage(deep=True).sum() / 1024**2,\n",
                "    pos_cash.memory_usage(deep=True).sum() / 1024**2,\n",
                "    credit_card.memory_usage(deep=True).sum() / 1024**2,\n",
                "    installments.memory_usage(deep=True).sum() / 1024**2\n",
                "]\n",
                "\n",
                "# Add key columns\n",
                "datasets_info['Primary_Key'] = [\n",
                "    'SK_ID_CURR',\n",
                "    'SK_ID_CURR, SK_ID_BUREAU',\n",
                "    'SK_ID_BUREAU',\n",
                "    'SK_ID_CURR, SK_ID_PREV',\n",
                "    'SK_ID_PREV',\n",
                "    'SK_ID_PREV',\n",
                "    'SK_ID_PREV'\n",
                "]\n",
                "\n",
                "print(\"\\nüìä Complete Dataset Overview:\")\n",
                "print(datasets_info.to_string(index=False))\n",
                "\n",
                "# Total statistics\n",
                "print(f\"\\nüìà Aggregate Statistics:\")\n",
                "print(f\"   ‚Üí Total Records Across All Tables: {datasets_info['Rows'].sum():,}\")\n",
                "print(f\"   ‚Üí Total Features: {datasets_info['Columns'].sum()}\")\n",
                "print(f\"   ‚Üí Total Memory Usage: {datasets_info['Memory_MB'].sum():.2f} MB\")\n",
                "\n",
                "# Save summary\n",
                "datasets_info.to_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\reports\\datasets_summary.csv\", index=False)\n",
                "print(\"\\n‚úì Dataset summary saved to reports/datasets_summary.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Data Relationship & Coverage Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "====================================================================================================\n",
                        "STEP 8: DATA RELATIONSHIP & COVERAGE ANALYSIS\n",
                        "====================================================================================================\n",
                        "\n",
                        "üìä Alternative Data Coverage Analysis:\n",
                        "              Dataset  Unique_IDs  Total_Records  Coverage_Percentage  Avg_Records_Per_ID\n",
                        "       Bureau History      305811        1716428                99.45                5.61\n",
                        "Previous Applications      338857        1670214               110.19                4.93\n",
                        "     POS/Cash Balance      936325       10001358               304.49               10.68\n",
                        "  Credit Card Balance      104307        3840312                33.92               36.82\n",
                        "Installments Payments      997752       13605401               324.46               13.64\n",
                        "\n",
                        "üîó Alternative Data Overlap:\n",
                        "                   Scenario  Count  Percentage\n",
                        "        No Alternative Data   2470        0.80\n",
                        "                Only Bureau  13984        4.55\n",
                        "         Only Previous Apps  41550       13.51\n",
                        "Both Bureau & Previous Apps 249507       81.14\n",
                        "\n",
                        "‚úì Coverage analysis saved\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*100)\n",
                "print(\"STEP 8: DATA RELATIONSHIP & COVERAGE ANALYSIS\")\n",
                "print(\"=\"*100)\n",
                "\n",
                "# Analyze how many applications have data in each table\n",
                "total_apps = len(train)\n",
                "\n",
                "# Bureau coverage\n",
                "apps_in_bureau = bureau['SK_ID_CURR'].nunique()\n",
                "bureau_coverage = (apps_in_bureau / total_apps) * 100\n",
                "\n",
                "# Previous application coverage\n",
                "apps_in_prev = previous_app['SK_ID_CURR'].nunique()\n",
                "prev_coverage = (apps_in_prev / total_apps) * 100\n",
                "\n",
                "# POS/Cash coverage (through previous applications)\n",
                "prev_ids_in_pos = pos_cash['SK_ID_PREV'].nunique()\n",
                "total_prev_ids = previous_app['SK_ID_PREV'].nunique()\n",
                "pos_coverage_of_prev = (prev_ids_in_pos / total_prev_ids) * 100 if total_prev_ids > 0 else 0\n",
                "\n",
                "# Credit card coverage\n",
                "prev_ids_in_cc = credit_card['SK_ID_PREV'].nunique()\n",
                "cc_coverage_of_prev = (prev_ids_in_cc / total_prev_ids) * 100 if total_prev_ids > 0 else 0\n",
                "\n",
                "# Installments coverage\n",
                "prev_ids_in_inst = installments['SK_ID_PREV'].nunique()\n",
                "inst_coverage_of_prev = (prev_ids_in_inst / total_prev_ids) * 100 if total_prev_ids > 0 else 0\n",
                "\n",
                "coverage_analysis = pd.DataFrame({\n",
                "    'Dataset': [\n",
                "        'Bureau History',\n",
                "        'Previous Applications',\n",
                "        'POS/Cash Balance',\n",
                "        'Credit Card Balance',\n",
                "        'Installments Payments'\n",
                "    ],\n",
                "    'Unique_IDs': [\n",
                "        apps_in_bureau,\n",
                "        apps_in_prev,\n",
                "        prev_ids_in_pos,\n",
                "        prev_ids_in_cc,\n",
                "        prev_ids_in_inst\n",
                "    ],\n",
                "    'Total_Records': [\n",
                "        len(bureau),\n",
                "        len(previous_app),\n",
                "        len(pos_cash),\n",
                "        len(credit_card),\n",
                "        len(installments)\n",
                "    ],\n",
                "    'Coverage_Percentage': [\n",
                "        bureau_coverage,\n",
                "        prev_coverage,\n",
                "        (prev_ids_in_pos / total_apps) * 100,\n",
                "        (prev_ids_in_cc / total_apps) * 100,\n",
                "        (prev_ids_in_inst / total_apps) * 100\n",
                "    ],\n",
                "    'Avg_Records_Per_ID': [\n",
                "        len(bureau) / apps_in_bureau if apps_in_bureau > 0 else 0,\n",
                "        len(previous_app) / apps_in_prev if apps_in_prev > 0 else 0,\n",
                "        len(pos_cash) / prev_ids_in_pos if prev_ids_in_pos > 0 else 0,\n",
                "        len(credit_card) / prev_ids_in_cc if prev_ids_in_cc > 0 else 0,\n",
                "        len(installments) / prev_ids_in_inst if prev_ids_in_inst > 0 else 0\n",
                "    ]\n",
                "})\n",
                "\n",
                "print(\"\\nüìä Alternative Data Coverage Analysis:\")\n",
                "print(coverage_analysis.to_string(index=False))\n",
                "\n",
                "# Check overlap\n",
                "has_bureau = train['SK_ID_CURR'].isin(bureau['SK_ID_CURR'])\n",
                "has_prev = train['SK_ID_CURR'].isin(previous_app['SK_ID_CURR'])\n",
                "\n",
                "overlap_analysis = pd.DataFrame({\n",
                "    'Scenario': [\n",
                "        'No Alternative Data',\n",
                "        'Only Bureau',\n",
                "        'Only Previous Apps',\n",
                "        'Both Bureau & Previous Apps'\n",
                "    ],\n",
                "    'Count': [\n",
                "        (~has_bureau & ~has_prev).sum(),\n",
                "        (has_bureau & ~has_prev).sum(),\n",
                "        (~has_bureau & has_prev).sum(),\n",
                "        (has_bureau & has_prev).sum()\n",
                "    ]\n",
                "})\n",
                "overlap_analysis['Percentage'] = (overlap_analysis['Count'] / total_apps) * 100\n",
                "\n",
                "print(\"\\nüîó Alternative Data Overlap:\")\n",
                "print(overlap_analysis.to_string(index=False))\n",
                "\n",
                "# Save coverage analysis\n",
                "coverage_analysis.to_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\reports\\data_coverage.csv\", index=False)\n",
                "overlap_analysis.to_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\reports\\data_overlap_analysis.csv\", index=False)\n",
                "\n",
                "print(\"\\n‚úì Coverage analysis saved\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Key Insights & Preliminary Findings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "====================================================================================================\n",
                        "STEP 9: KEY INSIGHTS & PRELIMINARY FINDINGS\n",
                        "====================================================================================================\n",
                        "\n",
                        "üí° KEY INSIGHTS:\n",
                        "   1. DEFAULT RATE: 8.07% - Indicates class imbalance requiring SMOTE/balancing\n",
                        "   2. MISSING DATA: 41 columns have >50% missing values - need robust imputation\n",
                        "   3. ALTERNATIVE DATA: 99.4% have bureau history, 110.2% have previous applications\n",
                        "   4. TARGET SEGMENT: 2,470 applications (0.8%) have NO alternative data\n",
                        "   5. DATA RICHNESS: 58,441,149 total records across all tables for feature engineering\n",
                        "   6. UTILITY PROXY: 10,001,358 POS/Cash balance records can proxy utility payment behavior\n",
                        "\n",
                        "‚úì Insights saved to reports/preliminary_insights.txt\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*100)\n",
                "print(\"STEP 9: KEY INSIGHTS & PRELIMINARY FINDINGS\")\n",
                "print(\"=\"*100)\n",
                "\n",
                "insights = []\n",
                "\n",
                "# Insight 1: Default rate\n",
                "insights.append(f\"1. DEFAULT RATE: {default_rate:.2f}% - Indicates class imbalance requiring SMOTE/balancing\")\n",
                "\n",
                "# Insight 2: Missing data\n",
                "high_missing_cols = len(missing_df[missing_df['Missing_Percentage'] > 50])\n",
                "insights.append(f\"2. MISSING DATA: {high_missing_cols} columns have >50% missing values - need robust imputation\")\n",
                "\n",
                "# Insight 3: Alternative data coverage\n",
                "insights.append(f\"3. ALTERNATIVE DATA: {bureau_coverage:.1f}% have bureau history, {prev_coverage:.1f}% have previous applications\")\n",
                "\n",
                "# Insight 4: No alternative data segment\n",
                "no_alt_data = (~has_bureau & ~has_prev).sum()\n",
                "no_alt_data_pct = (no_alt_data / total_apps) * 100\n",
                "insights.append(f\"4. TARGET SEGMENT: {no_alt_data:,} applications ({no_alt_data_pct:.1f}%) have NO alternative data\")\n",
                "\n",
                "# Insight 5: Data richness\n",
                "total_records = datasets_info['Rows'].sum()\n",
                "insights.append(f\"5. DATA RICHNESS: {total_records:,} total records across all tables for feature engineering\")\n",
                "\n",
                "# Insight 6: POS/Cash as utility proxy\n",
                "pos_records = len(pos_cash)\n",
                "insights.append(f\"6. UTILITY PROXY: {pos_records:,} POS/Cash balance records can proxy utility payment behavior\")\n",
                "\n",
                "# Print insights\n",
                "print(\"\\nüí° KEY INSIGHTS:\")\n",
                "for insight in insights:\n",
                "    print(f\"   {insight}\")\n",
                "\n",
                "# Save insights\n",
                "with open(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\reports\\preliminary_insights.txt\", 'w') as f:\n",
                "    f.write(\"PRELIMINARY INSIGHTS - DATA EXPLORATION\\n\")\n",
                "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
                "    for insight in insights:\n",
                "        f.write(insight + \"\\n\")\n",
                "\n",
                "print(\"\\n‚úì Insights saved to reports/preliminary_insights.txt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Generate Comprehensive Summary Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "====================================================================================================\n",
                        "STEP 10: GENERATING COMPREHENSIVE SUMMARY REPORT\n",
                        "====================================================================================================\n",
                        "\n",
                        "üìä COMPREHENSIVE STATISTICAL SUMMARY:\n",
                        "                                   Metric      Value\n",
                        "                       Total Applications    307,511\n",
                        "                    Total Features (Main)        122\n",
                        "                         Default Rate (%)       8.07\n",
                        "                       Repayment Rate (%)      91.93\n",
                        "                    Class Imbalance Ratio       1:11\n",
                        "                         Numeric Features        106\n",
                        "                     Categorical Features         16\n",
                        "                Columns with Missing Data         67\n",
                        "                Columns with >50% Missing         41\n",
                        "        Applications with Bureau Data (%)       99.4\n",
                        "     Applications with Previous Loans (%)      110.2\n",
                        "Applications with NO Alternative Data (%)        0.8\n",
                        "               Total Records (All Tables) 58,441,149\n",
                        "                  Total Memory Usage (MB)    7719.39\n",
                        "                 POS/Cash Balance Records 10,001,358\n",
                        "              Installment Payment Records 13,605,401\n",
                        "\n",
                        "‚úì Statistical summary saved to reports/statistical_summary.csv\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*100)\n",
                "print(\"STEP 10: GENERATING COMPREHENSIVE SUMMARY REPORT\")\n",
                "print(\"=\"*100)\n",
                "\n",
                "# Create comprehensive statistical summary\n",
                "summary_stats = pd.DataFrame({\n",
                "    'Metric': [\n",
                "        'Total Applications',\n",
                "        'Total Features (Main)',\n",
                "        'Default Rate (%)',\n",
                "        'Repayment Rate (%)',\n",
                "        'Class Imbalance Ratio',\n",
                "        'Numeric Features',\n",
                "        'Categorical Features',\n",
                "        'Columns with Missing Data',\n",
                "        'Columns with >50% Missing',\n",
                "        'Applications with Bureau Data (%)',\n",
                "        'Applications with Previous Loans (%)',\n",
                "        'Applications with NO Alternative Data (%)',\n",
                "        'Total Records (All Tables)',\n",
                "        'Total Memory Usage (MB)',\n",
                "        'POS/Cash Balance Records',\n",
                "        'Installment Payment Records'\n",
                "    ],\n",
                "    'Value': [\n",
                "        f\"{len(train):,}\",\n",
                "        f\"{train.shape[1]}\",\n",
                "        f\"{default_rate:.2f}\",\n",
                "        f\"{repayment_rate:.2f}\",\n",
                "        f\"1:{int(target_dist[0]/target_dist[1])}\",\n",
                "        f\"{len(numeric_cols)}\",\n",
                "        f\"{len(categorical_cols)}\",\n",
                "        f\"{len(missing_df)}\",\n",
                "        f\"{len(missing_df[missing_df['Missing_Percentage'] > 50])}\",\n",
                "        f\"{bureau_coverage:.1f}\",\n",
                "        f\"{prev_coverage:.1f}\",\n",
                "        f\"{no_alt_data_pct:.1f}\",\n",
                "        f\"{datasets_info['Rows'].sum():,}\",\n",
                "        f\"{datasets_info['Memory_MB'].sum():.2f}\",\n",
                "        f\"{len(pos_cash):,}\",\n",
                "        f\"{len(installments):,}\"\n",
                "    ]\n",
                "})\n",
                "\n",
                "print(\"\\nüìä COMPREHENSIVE STATISTICAL SUMMARY:\")\n",
                "print(summary_stats.to_string(index=False))\n",
                "\n",
                "# Save summary\n",
                "summary_stats.to_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\reports\\statistical_summary.csv\", index=False)\n",
                "\n",
                "print(\"\\n‚úì Statistical summary saved to reports/statistical_summary.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Analysis Complete - Next Steps"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "====================================================================================================\n",
                        "üìã DAY 1 DATA EXPLORATION COMPLETE\n",
                        "====================================================================================================\n",
                        "\n",
                        "‚úÖ COMPLETED TASKS:\n",
                        "   1. ‚úì Loaded and profiled 7 datasets\n",
                        "   2. ‚úì Analyzed target variable distribution\n",
                        "   3. ‚úì Comprehensive missing value analysis\n",
                        "   4. ‚úì Data type and structure analysis\n",
                        "   5. ‚úì Alternative data coverage analysis\n",
                        "   6. ‚úì Generated 8 detailed reports\n",
                        "\n",
                        "üìÅ GENERATED REPORTS:\n",
                        "    1. reports/column_descriptions.csv\n",
                        "    2. reports/target_distribution.csv\n",
                        "    3. reports/categorical_features_summary.csv\n",
                        "    4. reports/numeric_features_statistics.csv\n",
                        "    5. reports/missing_values_analysis.csv\n",
                        "    6. reports/datasets_summary.csv\n",
                        "    7. reports/data_coverage.csv\n",
                        "    8. reports/data_overlap_analysis.csv\n",
                        "    9. reports/preliminary_insights.txt\n",
                        "   10. reports/statistical_summary.csv\n",
                        "\n",
                        "üéØ NEXT STEPS (Day 2):\n",
                        "   ‚Üí Run 02_eda_analysis.ipynb for visualizations\n",
                        "   ‚Üí Create demographic analysis charts\n",
                        "   ‚Üí Financial feature distributions\n",
                        "   ‚Üí Correlation analysis\n",
                        "   ‚Üí Alternative data insights\n",
                        "\n",
                        "‚è±Ô∏è  Analysis completed at: 2026-02-15 23:42:25\n",
                        "====================================================================================================\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*100)\n",
                "print(\"üìã DAY 1 DATA EXPLORATION COMPLETE\")\n",
                "print(\"=\"*100)\n",
                "\n",
                "print(\"\\n‚úÖ COMPLETED TASKS:\")\n",
                "print(\"   1. ‚úì Loaded and profiled 7 datasets\")\n",
                "print(\"   2. ‚úì Analyzed target variable distribution\")\n",
                "print(\"   3. ‚úì Comprehensive missing value analysis\")\n",
                "print(\"   4. ‚úì Data type and structure analysis\")\n",
                "print(\"   5. ‚úì Alternative data coverage analysis\")\n",
                "print(\"   6. ‚úì Generated 8 detailed reports\")\n",
                "\n",
                "print(\"\\nüìÅ GENERATED REPORTS:\")\n",
                "reports = [\n",
                "    'column_descriptions.csv',\n",
                "    'target_distribution.csv',\n",
                "    'categorical_features_summary.csv',\n",
                "    'numeric_features_statistics.csv',\n",
                "    'missing_values_analysis.csv',\n",
                "    'datasets_summary.csv',\n",
                "    'data_coverage.csv',\n",
                "    'data_overlap_analysis.csv',\n",
                "    'preliminary_insights.txt',\n",
                "    'statistical_summary.csv'\n",
                "]\n",
                "for i, report in enumerate(reports, 1):\n",
                "    print(f\"   {i:2d}. reports/{report}\")\n",
                "\n",
                "print(\"\\nüéØ NEXT STEPS (Day 2):\")\n",
                "print(\"   ‚Üí Run 02_eda_analysis.ipynb for visualizations\")\n",
                "print(\"   ‚Üí Create demographic analysis charts\")\n",
                "print(\"   ‚Üí Financial feature distributions\")\n",
                "print(\"   ‚Üí Correlation analysis\")\n",
                "print(\"   ‚Üí Alternative data insights\")\n",
                "\n",
                "print(f\"\\n‚è±Ô∏è  Analysis completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
                "print(\"=\"*100)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
