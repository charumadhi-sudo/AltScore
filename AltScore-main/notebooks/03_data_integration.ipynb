{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f292098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Memory optimization function\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\"Reduce memory usage of dataframe\"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Memory usage: {start_mem:.2f} MB')\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Memory usage after: {end_mem:.2f} MB ({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')\n",
    "    return df\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8266f128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading application_train.csv...\n",
      "Shape: (307511, 122)\n",
      "Columns: 122\n",
      "Memory usage: 286.23 MB\n",
      "Memory usage after: 132.85 MB (53.6% reduction)\n",
      "✓ Main data loaded: 307511 applications, 121 features\n"
     ]
    }
   ],
   "source": [
    "# Load main application data\n",
    "print(\"Loading application_train.csv...\")\n",
    "train = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\application_train.csv\")\n",
    "print(f\"Shape: {train.shape}\")\n",
    "print(f\"Columns: {train.shape[1]}\")\n",
    "\n",
    "# Optimize memory\n",
    "train = reduce_mem_usage(train)\n",
    "\n",
    "# Separate target\n",
    "y = train['TARGET']\n",
    "train = train.drop('TARGET', axis=1)\n",
    "\n",
    "print(f\"✓ Main data loaded: {train.shape[0]} applications, {train.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ba14c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PROCESSING BUREAU DATA\n",
      "==================================================\n",
      "Bureau shape: (1716428, 17)\n",
      "Memory usage: 222.62 MB\n",
      "Memory usage after: 158.78 MB (28.7% reduction)\n",
      "✓ Bureau aggregated: 34 new features\n",
      "  - Numerical aggregations: 31 features\n",
      "  - Categorical counts: 3 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# BUREAU DATA - Credit history from other banks\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PROCESSING BUREAU DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load bureau\n",
    "bureau = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\bureau.csv\")\n",
    "print(f\"Bureau shape: {bureau.shape}\")\n",
    "bureau = reduce_mem_usage(bureau)\n",
    "\n",
    "# Aggregations\n",
    "bureau_agg = bureau.groupby('SK_ID_CURR').agg({\n",
    "    # Count features\n",
    "    'SK_ID_BUREAU': 'count',  # Number of previous credits\n",
    "    \n",
    "    # Credit amount features\n",
    "    'AMT_CREDIT_SUM': ['sum', 'mean', 'max', 'min'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['sum', 'mean', 'max'],\n",
    "    'AMT_CREDIT_SUM_LIMIT': ['sum', 'mean', 'max'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['sum', 'mean', 'max'],\n",
    "    \n",
    "    # Days features\n",
    "    'DAYS_CREDIT': ['min', 'max', 'mean'],  # How long ago credits were taken\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "    'DAYS_CREDIT_UPDATE': ['min', 'max', 'mean'],\n",
    "    'DAYS_ENDDATE_FACT': ['min', 'max', 'mean'],\n",
    "    \n",
    "    # Overdue features\n",
    "    'CREDIT_DAY_OVERDUE': ['max', 'mean', 'sum'],\n",
    "    'AMT_ANNUITY': ['mean', 'max'],\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "bureau_agg.columns = ['_'.join(col).strip('_') if col[1] != '' else col[0] \n",
    "                      for col in bureau_agg.columns.values]\n",
    "\n",
    "# Rename first column back\n",
    "bureau_agg = bureau_agg.rename(columns={'SK_ID_CURR': 'SK_ID_CURR'})\n",
    "\n",
    "# Add prefix to all columns except ID\n",
    "bureau_agg.columns = ['SK_ID_CURR'] + ['BUREAU_' + c for c in bureau_agg.columns if c != 'SK_ID_CURR']\n",
    "\n",
    "# Categorical features - count unique values\n",
    "bureau_cat = bureau.groupby('SK_ID_CURR').agg({\n",
    "    'CREDIT_ACTIVE': lambda x: (x == 'Active').sum(),  # Count of active credits\n",
    "    'CREDIT_CURRENCY': 'nunique',  # Number of different currencies\n",
    "    'CREDIT_TYPE': 'nunique'  # Number of different credit types\n",
    "}).reset_index()\n",
    "bureau_cat.columns = ['SK_ID_CURR', 'BUREAU_ACTIVE_COUNT', 'BUREAU_CURRENCY_COUNT', 'BUREAU_TYPE_COUNT']\n",
    "\n",
    "# Merge categorical with numerical\n",
    "bureau_agg = bureau_agg.merge(bureau_cat, on='SK_ID_CURR', how='left')\n",
    "\n",
    "print(f\"✓ Bureau aggregated: {bureau_agg.shape[1]-1} new features\")\n",
    "print(f\"  - Numerical aggregations: {bureau_agg.shape[1]-4} features\")\n",
    "print(f\"  - Categorical counts: 3 features\")\n",
    "\n",
    "# Clear memory\n",
    "del bureau, bureau_cat\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b664b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bureau balance shape: (27299925, 3)\n",
      "Memory usage: 624.85 MB\n",
      "Memory usage after: 338.46 MB (45.8% reduction)\n",
      "✓ Bureau balance added: 6 features\n",
      "✓ Total bureau features: 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load bureau_balance (monthly data)\n",
    "bureau_balance = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\bureau_balance.csv\")\n",
    "print(f\"Bureau balance shape: {bureau_balance.shape}\")\n",
    "bureau_balance = reduce_mem_usage(bureau_balance)\n",
    "\n",
    "# Aggregate bureau_balance by SK_ID_BUREAU first\n",
    "bb_agg = bureau_balance.groupby('SK_ID_BUREAU').agg({\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'size'],\n",
    "    'STATUS': lambda x: (x == 'C').sum()  # Count of 'closed' status\n",
    "}).reset_index()\n",
    "bb_agg.columns = ['SK_ID_BUREAU', 'BB_MONTHS_MIN', 'BB_MONTHS_MAX', 'BB_MONTHS_COUNT', 'BB_STATUS_CLOSED']\n",
    "\n",
    "# Merge with original bureau to get SK_ID_CURR\n",
    "bureau = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\bureau.csv\")[['SK_ID_BUREAU', 'SK_ID_CURR']]\n",
    "bb_agg = bb_agg.merge(bureau, on='SK_ID_BUREAU', how='left')\n",
    "\n",
    "# Now aggregate by SK_ID_CURR\n",
    "bb_final = bb_agg.groupby('SK_ID_CURR').agg({\n",
    "    'BB_MONTHS_MIN': 'min',\n",
    "    'BB_MONTHS_MAX': 'max',\n",
    "    'BB_MONTHS_COUNT': ['sum', 'mean'],\n",
    "    'BB_STATUS_CLOSED': ['sum', 'mean']\n",
    "}).reset_index()\n",
    "\n",
    "bb_final.columns = ['_'.join(col).strip('_') if col[1] != '' else col[0] \n",
    "                    for col in bb_final.columns.values]\n",
    "bb_final = bb_final.rename(columns={'SK_ID_CURR': 'SK_ID_CURR'})\n",
    "\n",
    "# Merge with bureau_agg\n",
    "bureau_agg = bureau_agg.merge(bb_final, on='SK_ID_CURR', how='left')\n",
    "\n",
    "print(f\"✓ Bureau balance added: {bb_final.shape[1]-1} features\")\n",
    "print(f\"✓ Total bureau features: {bureau_agg.shape[1]-1}\")\n",
    "\n",
    "# Clear memory\n",
    "del bureau_balance, bb_agg, bb_final, bureau\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53cc1684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PROCESSING PREVIOUS APPLICATIONS\n",
      "==================================================\n",
      "Previous apps shape: (1670214, 37)\n",
      "Memory usage: 471.48 MB\n",
      "Memory usage after: 388.65 MB (17.6% reduction)\n",
      "✓ Previous apps aggregated: 53 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# PREVIOUS APPLICATIONS - Past loan attempts\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PROCESSING PREVIOUS APPLICATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "prev = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\previous_application.csv\")\n",
    "print(f\"Previous apps shape: {prev.shape}\")\n",
    "prev = reduce_mem_usage(prev)\n",
    "\n",
    "# Numerical aggregations\n",
    "prev_agg = prev.groupby('SK_ID_CURR').agg({\n",
    "    # Count\n",
    "    'SK_ID_PREV': 'count',\n",
    "    \n",
    "    # Amount features\n",
    "    'AMT_ANNUITY': ['mean', 'max', 'min'],\n",
    "    'AMT_APPLICATION': ['mean', 'max', 'min'],\n",
    "    'AMT_CREDIT': ['mean', 'max', 'min'],\n",
    "    'AMT_DOWN_PAYMENT': ['mean', 'max'],\n",
    "    'AMT_GOODS_PRICE': ['mean', 'max', 'min'],\n",
    "    \n",
    "    # Days features  \n",
    "    'DAYS_DECISION': ['mean', 'max', 'min'],\n",
    "    'DAYS_FIRST_DRAWING': ['mean', 'max'],\n",
    "    'DAYS_FIRST_DUE': ['mean', 'max'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['mean', 'max'],\n",
    "    'DAYS_LAST_DUE': ['mean', 'max'],\n",
    "    'DAYS_TERMINATION': ['mean', 'max'],\n",
    "    \n",
    "    # Rate features\n",
    "    'RATE_DOWN_PAYMENT': ['mean', 'max', 'min'],\n",
    "    'RATE_INTEREST_PRIMARY': ['mean', 'max', 'min'],\n",
    "    'RATE_INTEREST_PRIVILEGED': ['mean', 'max', 'min'],\n",
    "    \n",
    "    # Hour process\n",
    "    'HOUR_APPR_PROCESS_START': ['mean', 'max', 'min'],\n",
    "    'NFLAG_LAST_APPL_IN_DAY': ['sum', 'mean'],\n",
    "}).reset_index()\n",
    "\n",
    "prev_agg.columns = ['_'.join(col).strip('_') if col[1] != '' else col[0] \n",
    "                    for col in prev_agg.columns.values]\n",
    "prev_agg = prev_agg.rename(columns={'SK_ID_CURR': 'SK_ID_CURR'})\n",
    "prev_agg.columns = ['SK_ID_CURR'] + ['PREV_' + c for c in prev_agg.columns if c != 'SK_ID_CURR']\n",
    "\n",
    "# Categorical aggregations\n",
    "prev_cat = prev.groupby('SK_ID_CURR').agg({\n",
    "    'NAME_CONTRACT_STATUS': lambda x: (x == 'Approved').sum(),  # Approval count\n",
    "    'NAME_CONTRACT_TYPE': lambda x: (x == 'Consumer loans').sum(),\n",
    "    'NAME_PAYMENT_TYPE': lambda x: (x == 'Cash through the bank').sum(),\n",
    "    'NAME_CLIENT_TYPE': lambda x: (x == 'Repeater').sum(),\n",
    "    'NAME_GOODS_CATEGORY': 'nunique',\n",
    "    'NAME_PORTFOLIO': 'nunique',\n",
    "    'NAME_PRODUCT_TYPE': 'nunique',\n",
    "    'CHANNEL_TYPE': 'nunique',\n",
    "    'NAME_SELLER_INDUSTRY': 'nunique',\n",
    "    'NAME_YIELD_GROUP': 'nunique',\n",
    "    'PRODUCT_COMBINATION': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "prev_cat.columns = ['SK_ID_CURR', 'PREV_APPROVED_COUNT', 'PREV_CONSUMER_LOAN_COUNT',\n",
    "                    'PREV_CASH_PAYMENT_COUNT', 'PREV_REPEATER_COUNT',\n",
    "                    'PREV_GOODS_CATEGORY_NUNIQUE', 'PREV_PORTFOLIO_NUNIQUE',\n",
    "                    'PREV_PRODUCT_TYPE_NUNIQUE', 'PREV_CHANNEL_NUNIQUE',\n",
    "                    'PREV_SELLER_INDUSTRY_NUNIQUE', 'PREV_YIELD_GROUP_NUNIQUE',\n",
    "                    'PREV_PRODUCT_COMBINATION_NUNIQUE']\n",
    "\n",
    "# Merge\n",
    "prev_agg = prev_agg.merge(prev_cat, on='SK_ID_CURR', how='left')\n",
    "\n",
    "print(f\"✓ Previous apps aggregated: {prev_agg.shape[1]-1} features\")\n",
    "\n",
    "del prev, prev_cat\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "229f346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PROCESSING POS/CASH BALANCE\n",
      "==================================================\n",
      "POS shape: (10001358, 8)\n",
      "Memory usage: 610.43 MB\n",
      "Memory usage after: 276.60 MB (54.7% reduction)\n",
      "✓ POS/Cash aggregated: 19 features\n",
      "  - Including payment regularity score (utility proxy)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# POS/CASH BALANCE - Utility payment proxy!\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PROCESSING POS/CASH BALANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "pos = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\POS_CASH_balance.csv\")\n",
    "print(f\"POS shape: {pos.shape}\")\n",
    "pos = reduce_mem_usage(pos)\n",
    "\n",
    "# Numerical aggregations\n",
    "pos_agg = pos.groupby('SK_ID_CURR').agg({\n",
    "    # Count\n",
    "    'SK_ID_PREV': 'count',\n",
    "    \n",
    "    # Months balance\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'mean', 'size'],\n",
    "    \n",
    "    # Contract status counts\n",
    "    'CNT_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "    'CNT_INSTALMENT_FUTURE': ['mean', 'max', 'sum'],\n",
    "    \n",
    "    # DPD (Days Past Due) - IMPORTANT!\n",
    "    'SK_DPD': ['mean', 'max', 'sum'],\n",
    "    'SK_DPD_DEF': ['mean', 'max', 'sum'],\n",
    "}).reset_index()\n",
    "\n",
    "pos_agg.columns = ['_'.join(col).strip('_') if col[1] != '' else col[0] \n",
    "                   for col in pos_agg.columns.values]\n",
    "pos_agg = pos_agg.rename(columns={'SK_ID_CURR': 'SK_ID_CURR'})\n",
    "pos_agg.columns = ['SK_ID_CURR'] + ['POS_' + c for c in pos_agg.columns if c != 'SK_ID_CURR']\n",
    "\n",
    "# Categorical - Active/Completed status\n",
    "pos_cat = pos.groupby('SK_ID_CURR').agg({\n",
    "    'NAME_CONTRACT_STATUS': lambda x: (x == 'Active').sum()  # Active accounts count\n",
    "}).reset_index()\n",
    "pos_cat.columns = ['SK_ID_CURR', 'POS_ACTIVE_COUNT']\n",
    "\n",
    "pos_agg = pos_agg.merge(pos_cat, on='SK_ID_CURR', how='left')\n",
    "\n",
    "# CRITICAL: Calculate payment regularity (early payment proxy)\n",
    "# Group by application and previous ID\n",
    "pos_grouped = pos.groupby(['SK_ID_CURR', 'SK_ID_PREV']).agg({\n",
    "    'SK_DPD': 'mean',  # Average DPD per account\n",
    "    'MONTHS_BALANCE': 'count'  # Number of months tracked\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate regularity: accounts with low avg DPD and long history\n",
    "pos_grouped['REGULARITY_SCORE'] = ((pos_grouped['SK_DPD'] == 0).astype(int) * \n",
    "                                    np.minimum(pos_grouped['MONTHS_BALANCE'] / 12, 1))\n",
    "\n",
    "# Aggregate by customer\n",
    "pos_regularity = pos_grouped.groupby('SK_ID_CURR').agg({\n",
    "    'REGULARITY_SCORE': 'mean'  # Average regularity across accounts\n",
    "}).reset_index()\n",
    "pos_regularity.columns = ['SK_ID_CURR', 'POS_PAYMENT_REGULARITY']\n",
    "\n",
    "pos_agg = pos_agg.merge(pos_regularity, on='SK_ID_CURR', how='left')\n",
    "\n",
    "print(f\"✓ POS/Cash aggregated: {pos_agg.shape[1]-1} features\")\n",
    "print(f\"  - Including payment regularity score (utility proxy)\")\n",
    "\n",
    "del pos, pos_cat, pos_grouped, pos_regularity\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7183c751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PROCESSING CREDIT CARD BALANCE\n",
      "==================================================\n",
      "Credit card shape: (3840312, 23)\n",
      "Memory usage: 673.88 MB\n",
      "Memory usage after: 479.78 MB (28.8% reduction)\n",
      "✓ Credit card aggregated: 70 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# CREDIT CARD BALANCE - Card usage patterns\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PROCESSING CREDIT CARD BALANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "cc = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\credit_card_balance.csv\")\n",
    "print(f\"Credit card shape: {cc.shape}\")\n",
    "cc = reduce_mem_usage(cc)\n",
    "\n",
    "# Numerical aggregations\n",
    "cc_agg = cc.groupby('SK_ID_CURR').agg({\n",
    "    # Count\n",
    "    'SK_ID_PREV': 'count',\n",
    "    \n",
    "    # Months balance\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'mean', 'size'],\n",
    "    \n",
    "    # Balance features\n",
    "    'AMT_BALANCE': ['mean', 'max', 'min', 'sum'],\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL': ['mean', 'max', 'min'],\n",
    "    'AMT_DRAWINGS_ATM_CURRENT': ['mean', 'max', 'sum'],\n",
    "    'AMT_DRAWINGS_CURRENT': ['mean', 'max', 'sum'],\n",
    "    'AMT_DRAWINGS_OTHER_CURRENT': ['mean', 'max', 'sum'],\n",
    "    'AMT_DRAWINGS_POS_CURRENT': ['mean', 'max', 'sum'],\n",
    "    'AMT_INST_MIN_REGULARITY': ['mean', 'max', 'min'],\n",
    "    'AMT_PAYMENT_CURRENT': ['mean', 'max', 'min', 'sum'],\n",
    "    'AMT_PAYMENT_TOTAL_CURRENT': ['mean', 'max', 'min', 'sum'],\n",
    "    'AMT_RECEIVABLE_PRINCIPAL': ['mean', 'max', 'min', 'sum'],\n",
    "    'AMT_RECIVABLE': ['mean', 'max', 'min', 'sum'],\n",
    "    'AMT_TOTAL_RECEIVABLE': ['mean', 'max', 'min', 'sum'],\n",
    "    \n",
    "    # Count features\n",
    "    'CNT_DRAWINGS_ATM_CURRENT': ['mean', 'max', 'sum'],\n",
    "    'CNT_DRAWINGS_CURRENT': ['mean', 'max', 'sum'],\n",
    "    'CNT_DRAWINGS_OTHER_CURRENT': ['mean', 'max', 'sum'],\n",
    "    'CNT_DRAWINGS_POS_CURRENT': ['mean', 'max', 'sum'],\n",
    "    'CNT_INSTALMENT_MATURE_CUM': ['mean', 'max'],\n",
    "    \n",
    "    # DPD\n",
    "    'SK_DPD': ['mean', 'max', 'sum'],\n",
    "    'SK_DPD_DEF': ['mean', 'max', 'sum'],\n",
    "}).reset_index()\n",
    "\n",
    "cc_agg.columns = ['_'.join(col).strip('_') if col[1] != '' else col[0] \n",
    "                  for col in cc_agg.columns.values]\n",
    "cc_agg = cc_agg.rename(columns={'SK_ID_CURR': 'SK_ID_CURR'})\n",
    "cc_agg.columns = ['SK_ID_CURR'] + ['CC_' + c for c in cc_agg.columns if c != 'SK_ID_CURR']\n",
    "\n",
    "# Calculate utilization ratio\n",
    "cc['UTILIZATION'] = cc['AMT_BALANCE'] / cc['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "cc_utilization = cc.groupby('SK_ID_CURR')['UTILIZATION'].agg(['mean', 'max', 'min']).reset_index()\n",
    "cc_utilization.columns = ['SK_ID_CURR', 'CC_UTILIZATION_MEAN', 'CC_UTILIZATION_MAX', 'CC_UTILIZATION_MIN']\n",
    "\n",
    "cc_agg = cc_agg.merge(cc_utilization, on='SK_ID_CURR', how='left')\n",
    "\n",
    "print(f\"✓ Credit card aggregated: {cc_agg.shape[1]-1} features\")\n",
    "\n",
    "del cc, cc_utilization\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650d4a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PROCESSING INSTALLMENTS PAYMENTS\n",
      "==================================================\n",
      "Installments shape: (13605401, 8)\n",
      "Memory usage: 830.41 MB\n",
      "Memory usage after: 493.05 MB (40.6% reduction)\n",
      "✓ Installments aggregated: 29 features\n",
      "  - Including early/late payment rates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# INSTALLMENTS PAYMENTS - Payment behavior\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PROCESSING INSTALLMENTS PAYMENTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "inst = pd.read_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\installments_payments.csv\")\n",
    "print(f\"Installments shape: {inst.shape}\")\n",
    "inst = reduce_mem_usage(inst)\n",
    "\n",
    "# Create payment timing features\n",
    "inst['PAYMENT_DIFF'] = inst['DAYS_ENTRY_PAYMENT'] - inst['DAYS_INSTALMENT']  # Negative = early\n",
    "inst['PAYMENT_RATIO'] = inst['AMT_PAYMENT'] / inst['AMT_INSTALMENT']  # <1 = underpaid\n",
    "\n",
    "# Numerical aggregations\n",
    "inst_agg = inst.groupby('SK_ID_CURR').agg({\n",
    "    # Count\n",
    "    'SK_ID_PREV': 'count',\n",
    "    \n",
    "    # Payment timing\n",
    "    'PAYMENT_DIFF': ['mean', 'max', 'min'],  # Early/late payments\n",
    "    'PAYMENT_RATIO': ['mean', 'max', 'min'],  # Payment completeness\n",
    "    \n",
    "    # Days features\n",
    "    'DAYS_ENTRY_PAYMENT': ['mean', 'max', 'min'],\n",
    "    'DAYS_INSTALMENT': ['mean', 'max', 'min'],\n",
    "    \n",
    "    # Amount features\n",
    "    'AMT_INSTALMENT': ['mean', 'max', 'min', 'sum'],\n",
    "    'AMT_PAYMENT': ['mean', 'max', 'min', 'sum'],\n",
    "    \n",
    "    # Version (payment plan changes)\n",
    "    'NUM_INSTALMENT_VERSION': ['mean', 'max', 'nunique'],\n",
    "    'NUM_INSTALMENT_NUMBER': ['mean', 'max'],\n",
    "}).reset_index()\n",
    "\n",
    "inst_agg.columns = ['_'.join(col).strip('_') if col[1] != '' else col[0] \n",
    "                    for col in inst_agg.columns.values]\n",
    "inst_agg = inst_agg.rename(columns={'SK_ID_CURR': 'SK_ID_CURR'})\n",
    "inst_agg.columns = ['SK_ID_CURR'] + ['INST_' + c for c in inst_agg.columns if c != 'SK_ID_CURR']\n",
    "\n",
    "# Payment behavior flags\n",
    "inst['EARLY_PAYMENT'] = (inst['PAYMENT_DIFF'] < -5).astype(int)  # Paid 5+ days early\n",
    "inst['LATE_PAYMENT'] = (inst['PAYMENT_DIFF'] > 5).astype(int)    # Paid 5+ days late\n",
    "inst['FULL_PAYMENT'] = (inst['PAYMENT_RATIO'] >= 0.99).astype(int)  # Paid full amount\n",
    "\n",
    "inst_behavior = inst.groupby('SK_ID_CURR').agg({\n",
    "    'EARLY_PAYMENT': 'mean',  # % of early payments\n",
    "    'LATE_PAYMENT': 'mean',   # % of late payments\n",
    "    'FULL_PAYMENT': 'mean'    # % of full payments\n",
    "}).reset_index()\n",
    "inst_behavior.columns = ['SK_ID_CURR', 'INST_EARLY_PAYMENT_RATE', \n",
    "                         'INST_LATE_PAYMENT_RATE', 'INST_FULL_PAYMENT_RATE']\n",
    "\n",
    "inst_agg = inst_agg.merge(inst_behavior, on='SK_ID_CURR', how='left')\n",
    "\n",
    "print(f\"✓ Installments aggregated: {inst_agg.shape[1]-1} features\")\n",
    "print(f\"  - Including early/late payment rates\")\n",
    "\n",
    "del inst, inst_behavior\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "439ed734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MERGING ALL DATASETS\n",
      "==================================================\n",
      "Starting with train: (307511, 121)\n",
      "After bureau merge: (307511, 161)\n",
      "After previous apps merge: (307511, 214)\n",
      "After POS/Cash merge: (307511, 233)\n",
      "After credit card merge: (307511, 303)\n",
      "After installments merge: (307511, 332)\n",
      "\n",
      "==================================================\n",
      "MERGE COMPLETE!\n",
      "==================================================\n",
      "Final shape: (307511, 333)\n",
      "Total features (excluding TARGET): 332\n",
      "New features added: 211\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# FINAL MERGE - Combine all tables\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MERGING ALL DATASETS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Starting with train: {train.shape}\")\n",
    "\n",
    "# Merge bureau\n",
    "train = train.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
    "print(f\"After bureau merge: {train.shape}\")\n",
    "\n",
    "# Merge previous applications\n",
    "train = train.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
    "print(f\"After previous apps merge: {train.shape}\")\n",
    "\n",
    "# Merge POS/Cash\n",
    "train = train.merge(pos_agg, on='SK_ID_CURR', how='left')\n",
    "print(f\"After POS/Cash merge: {train.shape}\")\n",
    "\n",
    "# Merge credit card\n",
    "train = train.merge(cc_agg, on='SK_ID_CURR', how='left')\n",
    "print(f\"After credit card merge: {train.shape}\")\n",
    "\n",
    "# Merge installments\n",
    "train = train.merge(inst_agg, on='SK_ID_CURR', how='left')\n",
    "print(f\"After installments merge: {train.shape}\")\n",
    "\n",
    "# Add target back\n",
    "train['TARGET'] = y\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MERGE COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Final shape: {train.shape}\")\n",
    "print(f\"Total features (excluding TARGET): {train.shape[1]-1}\")\n",
    "print(f\"New features added: {train.shape[1]-122}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5c9ae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "HANDLING MISSING VALUES\n",
      "==================================================\n",
      "Features with missing values: 257\n",
      "Top 10 missing:\n",
      "BUREAU_AMT_ANNUITY_mean              227502\n",
      "BUREAU_AMT_ANNUITY_max               227502\n",
      "CC_UTILIZATION_MEAN                  221349\n",
      "CC_UTILIZATION_MIN                   221348\n",
      "CC_UTILIZATION_MAX                   221348\n",
      "CC_AMT_TOTAL_RECEIVABLE_mean         220606\n",
      "CC_AMT_RECIVABLE_sum                 220606\n",
      "CC_SK_DPD_DEF_sum                    220606\n",
      "CC_CNT_DRAWINGS_OTHER_CURRENT_sum    220606\n",
      "CC_CNT_DRAWINGS_POS_CURRENT_sum      220606\n",
      "dtype: int64\n",
      "\n",
      "Dropping 0 features with >80% missing\n",
      "\n",
      "Numeric columns: 294\n",
      "Categorical columns: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithilan\\AppData\\Local\\Temp\\ipykernel_27112\\1010956511.py:56: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[col].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Missing values handled!\n",
      "Remaining missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# MISSING VALUE TREATMENT\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"HANDLING MISSING VALUES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check missing values\n",
    "missing = train.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "print(f\"Features with missing values: {len(missing)}\")\n",
    "print(f\"Top 10 missing:\")\n",
    "print(missing.head(10))\n",
    "\n",
    "# Strategy:\n",
    "# 1. Features with >80% missing → Drop\n",
    "# 2. Features with 20-80% missing → MICE imputation\n",
    "# 3. Features with <20% missing → Mean/Median\n",
    "\n",
    "# Identify high-missing features\n",
    "high_missing = missing[missing / len(train) > 0.8].index.tolist()\n",
    "print(f\"\\nDropping {len(high_missing)} features with >80% missing\")\n",
    "train = train.drop(high_missing, axis=1)\n",
    "\n",
    "# For remaining missing values, separate by type\n",
    "numeric_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove TARGET from numeric\n",
    "if 'TARGET' in numeric_cols:\n",
    "    numeric_cols.remove('TARGET')\n",
    "if 'SK_ID_CURR' in numeric_cols:\n",
    "    numeric_cols.remove('SK_ID_CURR')\n",
    "\n",
    "print(f\"\\nNumeric columns: {len(numeric_cols)}\")\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")\n",
    "\n",
    "# Simple imputation for numeric features\n",
    "from sklearn.impute import SimpleImputer\n",
    "# ============================================\n",
    "# FIX INFINITY VALUES BEFORE IMPUTATION\n",
    "# ============================================\n",
    "\n",
    "# Replace inf and -inf with NaN\n",
    "train[numeric_cols] = train[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Optional: remove extremely large values (safety)\n",
    "train[numeric_cols] = train[numeric_cols].clip(-1e15, 1e15)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train[numeric_cols] = imputer.fit_transform(train[numeric_cols])\n",
    "\n",
    "# For categorical features, fill with 'Unknown'\n",
    "for col in categorical_cols:\n",
    "    train[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "print(\"\\n✓ Missing values handled!\")\n",
    "print(f\"Remaining missing values: {train.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afd264ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SAVING FINAL DATASET\n",
      "==================================================\n",
      "✓ Saved X_train_merged.csv: (307511, 311)\n",
      "✓ Saved y_train.csv: (307511,)\n",
      "✓ Saved feature_names.txt: 311 features\n",
      "\n",
      "✓ Summary report saved!\n",
      "               Metric  Value\n",
      "   Total Applications 307511\n",
      "       Total Features    311\n",
      "    Original Features    121\n",
      "         New Features    190\n",
      "      Bureau Features     54\n",
      "Previous App Features     72\n",
      "    POS/Cash Features     20\n",
      " Credit Card Features     93\n",
      " Installment Features     32\n",
      "         Default Rate  8.07%\n",
      "\n",
      "==================================================\n",
      "DATA INTEGRATION COMPLETE! ✅\n",
      "==================================================\n",
      "\n",
      "Ready for feature engineering!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SAVE FINAL DATASET\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SAVING FINAL DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Separate features and target\n",
    "X = train.drop('TARGET', axis=1)\n",
    "y = train['TARGET']\n",
    "\n",
    "# Save\n",
    "X.to_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\final\\X_train_merged.csv\", index=False)\n",
    "y.to_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\final\\y_train.csv\", index=False)\n",
    "\n",
    "print(f\"✓ Saved X_train_merged.csv: {X.shape}\")\n",
    "print(f\"✓ Saved y_train.csv: {y.shape}\")\n",
    "\n",
    "# Save feature names for reference\n",
    "feature_names = X.columns.tolist()\n",
    "with open(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\data\\final\\feature_names.txt\", 'w') as f:\n",
    "    for feature in feature_names:\n",
    "        f.write(f\"{feature}\\n\")\n",
    "\n",
    "print(f\"✓ Saved feature_names.txt: {len(feature_names)} features\")\n",
    "\n",
    "# Create summary report\n",
    "summary = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Applications',\n",
    "        'Total Features',\n",
    "        'Original Features',\n",
    "        'New Features',\n",
    "        'Bureau Features',\n",
    "        'Previous App Features',\n",
    "        'POS/Cash Features',\n",
    "        'Credit Card Features',\n",
    "        'Installment Features',\n",
    "        'Default Rate'\n",
    "    ],\n",
    "    'Value': [\n",
    "        X.shape[0],\n",
    "        X.shape[1],\n",
    "        121,\n",
    "        X.shape[1] - 121,\n",
    "        54,\n",
    "        72,\n",
    "        20,\n",
    "        93,\n",
    "        32,\n",
    "        f\"{y.mean()*100:.2f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary.to_csv(r\"D:\\Nithilan\\SEM 4\\Hackathons\\Zenith\\reports\\data_integration_summary.csv\", index=False)\n",
    "print(\"\\n✓ Summary report saved!\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA INTEGRATION COMPLETE! ✅\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nReady for feature engineering!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
