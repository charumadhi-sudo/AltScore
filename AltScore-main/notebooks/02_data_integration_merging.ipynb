{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š AltScore â€” Data Integration & Merging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries loaded successfully!\n",
      "Pandas: 2.3.3, NumPy: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "print('âœ… Libraries loaded successfully!')\n",
    "print(f'Pandas: {pd.__version__}, NumPy: {np.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 1 â€” Load Main Application Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = '../data/raw/'  # Change this to where your CSV files are stored\n",
    "\n",
    "print('ðŸ“‚ Loading main application data...')\n",
    "app_train = pd.read_csv(DATA_DIR + 'application_train.csv')\n",
    "\n",
    "print(f'âœ… Loaded: {app_train.shape[0]:,} applications Ã— {app_train.shape[1]} features')\n",
    "print(f'Target (TARGET): {app_train[\"TARGET\"].value_counts().to_dict()}')\n",
    "print(f'Default rate: {app_train[\"TARGET\"].mean()*100:.2f}%')\n",
    "\n",
    "# Keep a copy of the target variable\n",
    "y_train = app_train['TARGET'].copy()\n",
    "\n",
    "print('\\n=== First 3 rows ===')\n",
    "display(app_train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##  STEP 2 â€” Load & Aggregate Bureau Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ“‚ Loading bureau data...')\n",
    "bureau = pd.read_csv(DATA_DIR + 'bureau.csv')\n",
    "\n",
    "print(f'âœ… Loaded: {bureau.shape[0]:,} bureau records')\n",
    "print(f'Unique customers: {bureau[\"SK_ID_CURR\"].nunique():,}')\n",
    "print(f'Coverage: {bureau[\"SK_ID_CURR\"].nunique() / app_train.shape[0] * 100:.1f}% of applications')\n",
    "\n",
    "display(bureau.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Aggregate Bureau Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('ðŸ”§ Aggregating bureau data by customer...')\n",
    "\n",
    "# Count of bureau records per customer\n",
    "bureau_agg = bureau.groupby('SK_ID_CURR').agg({\n",
    "    'SK_ID_BUREAU': 'count',  # Number of credit lines\n",
    "}).rename(columns={'SK_ID_BUREAU': 'BUREAU_SK_ID_BUREAU_count'})\n",
    "\n",
    "# Aggregate numeric columns\n",
    "numeric_cols = bureau.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols.remove('SK_ID_CURR')  # Don't aggregate the ID itself\n",
    "numeric_cols.remove('SK_ID_BUREAU')\n",
    "\n",
    "for col in numeric_cols:\n",
    "    # Sum, mean, max, min for credit amounts and days\n",
    "    if 'AMT' in col or 'CNT' in col:\n",
    "        bureau_agg[f'BUREAU_{col}_sum'] = bureau.groupby('SK_ID_CURR')[col].sum()\n",
    "        bureau_agg[f'BUREAU_{col}_mean'] = bureau.groupby('SK_ID_CURR')[col].mean()\n",
    "        bureau_agg[f'BUREAU_{col}_max'] = bureau.groupby('SK_ID_CURR')[col].max()\n",
    "        if 'AMT' in col:\n",
    "            bureau_agg[f'BUREAU_{col}_min'] = bureau.groupby('SK_ID_CURR')[col].min()\n",
    "    elif 'DAYS' in col:\n",
    "        bureau_agg[f'BUREAU_{col}_min'] = bureau.groupby('SK_ID_CURR')[col].min()\n",
    "        bureau_agg[f'BUREAU_{col}_max'] = bureau.groupby('SK_ID_CURR')[col].max()\n",
    "        bureau_agg[f'BUREAU_{col}_mean'] = bureau.groupby('SK_ID_CURR')[col].mean()\n",
    "\n",
    "# Count active credits\n",
    "if 'CREDIT_ACTIVE' in bureau.columns:\n",
    "    bureau_agg['BUREAU_ACTIVE_COUNT'] = bureau[bureau['CREDIT_ACTIVE'] == 'Active'].groupby('SK_ID_CURR').size()\n",
    "\n",
    "# Count different credit types\n",
    "if 'CREDIT_CURRENCY' in bureau.columns:\n",
    "    bureau_agg['BUREAU_CURRENCY_COUNT'] = bureau.groupby('SK_ID_CURR')['CREDIT_CURRENCY'].nunique()\n",
    "if 'CREDIT_TYPE' in bureau.columns:\n",
    "    bureau_agg['BUREAU_TYPE_COUNT'] = bureau.groupby('SK_ID_CURR')['CREDIT_TYPE'].nunique()\n",
    "\n",
    "bureau_agg = bureau_agg.reset_index()\n",
    "\n",
    "print(f'âœ… Created {bureau_agg.shape[1]-1} bureau aggregated features')\n",
    "print(f'Customers with bureau data: {bureau_agg.shape[0]:,}')\n",
    "\n",
    "display(bureau_agg.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 â€” Bureau Balance (Monthly Credit Behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ“‚ Loading bureau_balance data...')\n",
    "bureau_balance = pd.read_csv(DATA_DIR + 'bureau_balance.csv')\n",
    "\n",
    "print(f'âœ… Loaded: {bureau_balance.shape[0]:,} monthly balance records')\n",
    "display(bureau_balance.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Aggregate Bureau Balance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('ðŸ”§ Aggregating bureau_balance...')\n",
    "\n",
    "bb_agg = bureau_balance.groupby('SK_ID_BUREAU').agg({\n",
    "    'MONTHS_BALANCE': ['min', 'max'],  # Range of months\n",
    "}).reset_index()\n",
    "bb_agg.columns = ['SK_ID_BUREAU', 'BB_MONTHS_MIN_min', 'BB_MONTHS_MAX_max']\n",
    "\n",
    "# Count records per bureau ID\n",
    "bb_counts = bureau_balance.groupby('SK_ID_BUREAU').size().reset_index(name='BB_MONTHS_COUNT_sum')\n",
    "bb_agg = bb_agg.merge(bb_counts, on='SK_ID_BUREAU', how='left')\n",
    "bb_agg['BB_MONTHS_COUNT_mean'] = bb_agg['BB_MONTHS_COUNT_sum'] / bb_agg['BB_MONTHS_COUNT_sum']\n",
    "\n",
    "# Status analysis (if STATUS column exists)\n",
    "if 'STATUS' in bureau_balance.columns:\n",
    "    status_closed = bureau_balance[bureau_balance['STATUS'] == 'C'].groupby('SK_ID_BUREAU').size().reset_index(name='BB_STATUS_CLOSED_sum')\n",
    "    bb_agg = bb_agg.merge(status_closed, on='SK_ID_BUREAU', how='left')\n",
    "    bb_agg['BB_STATUS_CLOSED_mean'] = bb_agg['BB_STATUS_CLOSED_sum'] / bb_agg['BB_MONTHS_COUNT_sum']\n",
    "    bb_agg['BB_STATUS_CLOSED_sum'].fillna(0, inplace=True)\n",
    "    bb_agg['BB_STATUS_CLOSED_mean'].fillna(0, inplace=True)\n",
    "\n",
    "# Merge back to bureau data\n",
    "bureau_with_balance = bureau[['SK_ID_CURR', 'SK_ID_BUREAU']].merge(bb_agg, on='SK_ID_BUREAU', how='left')\n",
    "bb_final = bureau_with_balance.groupby('SK_ID_CURR').mean().reset_index()\n",
    "\n",
    "print(f'âœ… Created {bb_final.shape[1]-1} bureau_balance features')\n",
    "\n",
    "# Merge bureau + bureau_balance\n",
    "bureau_full = bureau_agg.merge(bb_final, on='SK_ID_CURR', how='left')\n",
    "print(f'âœ… Combined bureau features: {bureau_full.shape[1]-1} total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 3 â€” Load & Aggregate Previous Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ“‚ Loading previous_application data...')\n",
    "prev_app = pd.read_csv(DATA_DIR + 'previous_application.csv')\n",
    "\n",
    "print(f'âœ… Loaded: {prev_app.shape[0]:,} previous applications')\n",
    "print(f'Unique customers: {prev_app[\"SK_ID_CURR\"].nunique():,}')\n",
    "print(f'Coverage: {prev_app[\"SK_ID_CURR\"].nunique() / app_train.shape[0] * 100:.1f}% of applications')\n",
    "\n",
    "display(prev_app.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Aggregate Previous Applications â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('ðŸ”§ Aggregating previous_application...')\n",
    "\n",
    "# Count of previous applications\n",
    "prev_agg = prev_app.groupby('SK_ID_CURR').agg({\n",
    "    'SK_ID_PREV': 'count'\n",
    "}).rename(columns={'SK_ID_PREV': 'PREV_SK_ID_PREV_count'})\n",
    "\n",
    "# Aggregate numeric columns\n",
    "numeric_cols = prev_app.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c not in ['SK_ID_CURR', 'SK_ID_PREV']]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if 'AMT' in col:\n",
    "        prev_agg[f'PREV_{col}_mean'] = prev_app.groupby('SK_ID_CURR')[col].mean()\n",
    "        prev_agg[f'PREV_{col}_max'] = prev_app.groupby('SK_ID_CURR')[col].max()\n",
    "        prev_agg[f'PREV_{col}_min'] = prev_app.groupby('SK_ID_CURR')[col].min()\n",
    "    elif 'DAYS' in col:\n",
    "        prev_agg[f'PREV_{col}_mean'] = prev_app.groupby('SK_ID_CURR')[col].mean()\n",
    "        prev_agg[f'PREV_{col}_max'] = prev_app.groupby('SK_ID_CURR')[col].max()\n",
    "        prev_agg[f'PREV_{col}_min'] = prev_app.groupby('SK_ID_CURR')[col].min()\n",
    "    elif 'RATE' in col or 'HOUR' in col:\n",
    "        prev_agg[f'PREV_{col}_mean'] = prev_app.groupby('SK_ID_CURR')[col].mean()\n",
    "        prev_agg[f'PREV_{col}_max'] = prev_app.groupby('SK_ID_CURR')[col].max()\n",
    "        prev_agg[f'PREV_{col}_min'] = prev_app.groupby('SK_ID_CURR')[col].min()\n",
    "    elif 'NFLAG' in col or 'FLAG' in col:\n",
    "        prev_agg[f'PREV_{col}_sum'] = prev_app.groupby('SK_ID_CURR')[col].sum()\n",
    "        prev_agg[f'PREV_{col}_mean'] = prev_app.groupby('SK_ID_CURR')[col].mean()\n",
    "\n",
    "# Categorical aggregations\n",
    "if 'NAME_CONTRACT_STATUS' in prev_app.columns:\n",
    "    prev_agg['PREV_APPROVED_COUNT'] = prev_app[prev_app['NAME_CONTRACT_STATUS'] == 'Approved'].groupby('SK_ID_CURR').size()\n",
    "if 'NAME_CONTRACT_TYPE' in prev_app.columns:\n",
    "    prev_agg['PREV_CONSUMER_LOAN_COUNT'] = prev_app[prev_app['NAME_CONTRACT_TYPE'] == 'Consumer loans'].groupby('SK_ID_CURR').size()\n",
    "if 'NAME_PAYMENT_TYPE' in prev_app.columns:\n",
    "    prev_agg['PREV_CASH_PAYMENT_COUNT'] = prev_app[prev_app['NAME_PAYMENT_TYPE'] == 'Cash through the bank'].groupby('SK_ID_CURR').size()\n",
    "if 'NAME_CLIENT_TYPE' in prev_app.columns:\n",
    "    prev_agg['PREV_REPEATER_COUNT'] = prev_app[prev_app['NAME_CLIENT_TYPE'] == 'Repeater'].groupby('SK_ID_CURR').size()\n",
    "\n",
    "# Diversity metrics (number of unique categories)\n",
    "for col in ['NAME_GOODS_CATEGORY', 'NAME_PORTFOLIO', 'NAME_PRODUCT_TYPE', 'CHANNEL_TYPE', 'NAME_SELLER_INDUSTRY', 'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION']:\n",
    "    if col in prev_app.columns:\n",
    "        prev_agg[f'PREV_{col}_NUNIQUE'] = prev_app.groupby('SK_ID_CURR')[col].nunique()\n",
    "\n",
    "prev_agg = prev_agg.reset_index()\n",
    "prev_agg.fillna(0, inplace=True)\n",
    "\n",
    "print(f'âœ… Created {prev_agg.shape[1]-1} previous_application features')\n",
    "print(f'Customers with previous apps: {prev_agg.shape[0]:,}')\n",
    "\n",
    "display(prev_agg.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##  STEP 4 â€” Load & Aggregate POS Cash Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ“‚ Loading POS_CASH_balance data...')\n",
    "pos_cash = pd.read_csv(DATA_DIR + 'POS_CASH_balance.csv')\n",
    "\n",
    "print(f'âœ… Loaded: {pos_cash.shape[0]:,} POS/cash balance records')\n",
    "print(f'Unique customers: {pos_cash[\"SK_ID_CURR\"].nunique():,}')\n",
    "\n",
    "display(pos_cash.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Aggregate POS Cash Balance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('ðŸ”§ Aggregating POS_CASH_balance...')\n",
    "\n",
    "# First aggregate by SK_ID_PREV (loan level)\n",
    "pos_agg = pos_cash.groupby('SK_ID_PREV').agg({\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'mean', 'size'],\n",
    "    'CNT_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "    'CNT_INSTALMENT_FUTURE': ['mean', 'max', 'sum'],\n",
    "    'SK_DPD': ['mean', 'max', 'sum'],\n",
    "    'SK_DPD_DEF': ['mean', 'max', 'sum'],\n",
    "}).reset_index()\n",
    "\n",
    "pos_agg.columns = ['SK_ID_PREV', \n",
    "                   'POS_MONTHS_BALANCE_min', 'POS_MONTHS_BALANCE_max', 'POS_MONTHS_BALANCE_mean', 'POS_MONTHS_BALANCE_size',\n",
    "                   'POS_CNT_INSTALMENT_mean', 'POS_CNT_INSTALMENT_max', 'POS_CNT_INSTALMENT_sum',\n",
    "                   'POS_CNT_INSTALMENT_FUTURE_mean', 'POS_CNT_INSTALMENT_FUTURE_max', 'POS_CNT_INSTALMENT_FUTURE_sum',\n",
    "                   'POS_SK_DPD_mean', 'POS_SK_DPD_max', 'POS_SK_DPD_sum',\n",
    "                   'POS_SK_DPD_DEF_mean', 'POS_SK_DPD_DEF_max', 'POS_SK_DPD_DEF_sum']\n",
    "\n",
    "# Count active loans (NAME_CONTRACT_STATUS = 'Active')\n",
    "if 'NAME_CONTRACT_STATUS' in pos_cash.columns:\n",
    "    active_count = pos_cash[pos_cash['NAME_CONTRACT_STATUS'] == 'Active'].groupby('SK_ID_PREV')['SK_ID_PREV'].count().reset_index(name='POS_ACTIVE_COUNT')\n",
    "    pos_agg = pos_agg.merge(active_count, on='SK_ID_PREV', how='left')\n",
    "    pos_agg['POS_ACTIVE_COUNT'].fillna(0, inplace=True)\n",
    "\n",
    "# Payment regularity score\n",
    "pos_agg['POS_PAYMENT_REGULARITY'] = 1.0 - (pos_agg['POS_SK_DPD_sum'] / (pos_agg['POS_MONTHS_BALANCE_size'] + 1e-5))\n",
    "\n",
    "# Get SK_ID_CURR mapping\n",
    "pos_curr_map = pos_cash[['SK_ID_CURR', 'SK_ID_PREV']].drop_duplicates()\n",
    "pos_agg = pos_curr_map.merge(pos_agg, on='SK_ID_PREV', how='left')\n",
    "\n",
    "# Aggregate to customer level\n",
    "pos_final = pos_agg.groupby('SK_ID_CURR').agg({\n",
    "    'SK_ID_PREV': 'count',\n",
    "    'POS_MONTHS_BALANCE_min': 'min',\n",
    "    'POS_MONTHS_BALANCE_max': 'max',\n",
    "    'POS_MONTHS_BALANCE_mean': 'mean',\n",
    "    'POS_MONTHS_BALANCE_size': 'mean',\n",
    "    'POS_CNT_INSTALMENT_mean': 'mean',\n",
    "    'POS_CNT_INSTALMENT_max': 'max',\n",
    "    'POS_CNT_INSTALMENT_sum': 'sum',\n",
    "    'POS_CNT_INSTALMENT_FUTURE_mean': 'mean',\n",
    "    'POS_CNT_INSTALMENT_FUTURE_max': 'max',\n",
    "    'POS_CNT_INSTALMENT_FUTURE_sum': 'sum',\n",
    "    'POS_SK_DPD_mean': 'mean',\n",
    "    'POS_SK_DPD_max': 'max',\n",
    "    'POS_SK_DPD_sum': 'sum',\n",
    "    'POS_SK_DPD_DEF_mean': 'mean',\n",
    "    'POS_SK_DPD_DEF_max': 'max',\n",
    "    'POS_SK_DPD_DEF_sum': 'sum',\n",
    "    'POS_ACTIVE_COUNT': 'sum',\n",
    "    'POS_PAYMENT_REGULARITY': 'mean',\n",
    "}).reset_index()\n",
    "\n",
    "pos_final.rename(columns={'SK_ID_PREV': 'POS_SK_ID_PREV_count'}, inplace=True)\n",
    "\n",
    "print(f'âœ… Created {pos_final.shape[1]-1} POS_CASH features')\n",
    "print(f'Customers with POS data: {pos_final.shape[0]:,}')\n",
    "\n",
    "display(pos_final.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 5 â€” Load & Aggregate Credit Card Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ“‚ Loading credit_card_balance data...')\n",
    "cc_bal = pd.read_csv(DATA_DIR + 'credit_card_balance.csv')\n",
    "\n",
    "print(f'âœ… Loaded: {cc_bal.shape[0]:,} credit card balance records')\n",
    "print(f'Unique customers: {cc_bal[\"SK_ID_CURR\"].nunique():,}')\n",
    "\n",
    "display(cc_bal.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Aggregate Credit Card Balance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('ðŸ”§ Aggregating credit_card_balance...')\n",
    "\n",
    "# Aggregate by SK_ID_PREV first\n",
    "cc_prev_agg = cc_bal.groupby('SK_ID_PREV').agg({\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'mean', 'size'],\n",
    "    'AMT_BALANCE': ['mean', 'max', 'min', 'sum'],\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL': ['mean', 'max', 'min'],\n",
    "    'AMT_DRAWINGS_ATM_CURRENT': 'sum',\n",
    "    'AMT_DRAWINGS_CURRENT': ['mean', 'max', 'sum'],\n",
    "    'AMT_DRAWINGS_OTHER_CURRENT': 'sum',\n",
    "    'AMT_DRAWINGS_POS_CURRENT': 'sum',\n",
    "    'AMT_INST_MIN_REGULARITY': ['mean', 'max', 'min'],\n",
    "    'AMT_PAYMENT_CURRENT': 'sum',\n",
    "    'AMT_PAYMENT_TOTAL_CURRENT': ['mean', 'max', 'min', 'sum'],\n",
    "    'AMT_RECEIVABLE_PRINCIPAL': ['mean', 'max', 'min', 'sum'],\n",
    "    'AMT_RECIVABLE': ['mean', 'max', 'min', 'sum'],\n",
    "    'AMT_TOTAL_RECEIVABLE': ['mean', 'max', 'min', 'sum'],\n",
    "    'CNT_DRAWINGS_ATM_CURRENT': 'sum',\n",
    "    'CNT_DRAWINGS_CURRENT': ['mean', 'max', 'sum'],\n",
    "    'CNT_DRAWINGS_OTHER_CURRENT': 'sum',\n",
    "    'CNT_DRAWINGS_POS_CURRENT': 'sum',\n",
    "    'CNT_INSTALMENT_MATURE_CUM': ['mean', 'max'],\n",
    "    'SK_DPD': ['mean', 'max', 'sum'],\n",
    "    'SK_DPD_DEF': ['mean', 'max', 'sum'],\n",
    "}).reset_index()\n",
    "\n",
    "cc_prev_agg.columns = ['_'.join(col).strip('_') if col[1] else col[0] for col in cc_prev_agg.columns.values]\n",
    "cc_prev_agg.columns = ['SK_ID_PREV'] + ['CC_' + c for c in cc_prev_agg.columns[1:]]\n",
    "\n",
    "# Credit utilization\n",
    "cc_prev_agg['CC_UTILIZATION_MEAN'] = cc_prev_agg['CC_AMT_BALANCE_mean'] / (cc_prev_agg['CC_AMT_CREDIT_LIMIT_ACTUAL_mean'] + 1e-5)\n",
    "cc_prev_agg['CC_UTILIZATION_MAX'] = cc_prev_agg['CC_AMT_BALANCE_max'] / (cc_prev_agg['CC_AMT_CREDIT_LIMIT_ACTUAL_max'] + 1e-5)\n",
    "cc_prev_agg['CC_UTILIZATION_MIN'] = cc_prev_agg['CC_AMT_BALANCE_min'] / (cc_prev_agg['CC_AMT_CREDIT_LIMIT_ACTUAL_min'] + 1e-5)\n",
    "\n",
    "# Map to SK_ID_CURR\n",
    "cc_curr_map = cc_bal[['SK_ID_CURR', 'SK_ID_PREV']].drop_duplicates()\n",
    "cc_prev_agg = cc_curr_map.merge(cc_prev_agg, on='SK_ID_PREV', how='left')\n",
    "\n",
    "# Aggregate to customer level\n",
    "cc_final = cc_prev_agg.groupby('SK_ID_CURR').mean().reset_index()\n",
    "cc_final.rename(columns={'SK_ID_PREV': 'CC_SK_ID_PREV_count'}, inplace=True)\n",
    "\n",
    "print(f'âœ… Created {cc_final.shape[1]-1} credit_card features')\n",
    "print(f'Customers with CC data: {cc_final.shape[0]:,}')\n",
    "\n",
    "display(cc_final.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 6 â€” Load & Aggregate Installments Payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ“‚ Loading installments_payments data...')\n",
    "inst_pay = pd.read_csv(DATA_DIR + 'installments_payments.csv')\n",
    "\n",
    "print(f'âœ… Loaded: {inst_pay.shape[0]:,} installment payment records')\n",
    "print(f'Unique customers: {inst_pay[\"SK_ID_CURR\"].nunique():,}')\n",
    "\n",
    "display(inst_pay.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Aggregate Installments Payments â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('ðŸ”§ Aggregating installments_payments...')\n",
    "\n",
    "# Payment difference (paid - expected)\n",
    "inst_pay['PAYMENT_DIFF'] = inst_pay['AMT_PAYMENT'] - inst_pay['AMT_INSTALMENT']\n",
    "inst_pay['PAYMENT_RATIO'] = inst_pay['AMT_PAYMENT'] / (inst_pay['AMT_INSTALMENT'] + 1e-5)\n",
    "\n",
    "# Aggregate by SK_ID_PREV\n",
    "inst_prev_agg = inst_pay.groupby('SK_ID_PREV').agg({\n",
    "    'NUM_INSTALMENT_VERSION': ['mean', 'max', 'nunique'],\n",
    "    'NUM_INSTALMENT_NUMBER': ['mean', 'max'],\n",
    "    'DAYS_INSTALMENT': ['mean', 'max', 'min'],\n",
    "    'DAYS_ENTRY_PAYMENT': ['mean', 'max', 'min'],\n",
    "    'AMT_INSTALMENT': ['mean', 'max', 'min', 'sum'],\n",
    "    'AMT_PAYMENT': ['mean', 'max', 'min', 'sum'],\n",
    "    'PAYMENT_DIFF': ['mean', 'max', 'min'],\n",
    "    'PAYMENT_RATIO': ['mean', 'max', 'min'],\n",
    "}).reset_index()\n",
    "\n",
    "inst_prev_agg.columns = ['_'.join(col).strip('_') if col[1] else col[0] for col in inst_prev_agg.columns.values]\n",
    "inst_prev_agg.columns = ['SK_ID_PREV'] + ['INST_' + c for c in inst_prev_agg.columns[1:]]\n",
    "\n",
    "# Payment behavior flags\n",
    "# Early payment: paid before due date\n",
    "early_payments = inst_pay[inst_pay['DAYS_ENTRY_PAYMENT'] < inst_pay['DAYS_INSTALMENT']].groupby('SK_ID_PREV').size()\n",
    "# Late payment: paid after due date\n",
    "late_payments = inst_pay[inst_pay['DAYS_ENTRY_PAYMENT'] > inst_pay['DAYS_INSTALMENT']].groupby('SK_ID_PREV').size()\n",
    "# Full payment: paid >= expected\n",
    "full_payments = inst_pay[inst_pay['AMT_PAYMENT'] >= inst_pay['AMT_INSTALMENT']].groupby('SK_ID_PREV').size()\n",
    "# Total payments\n",
    "total_payments = inst_pay.groupby('SK_ID_PREV').size()\n",
    "\n",
    "inst_prev_agg['INST_EARLY_PAYMENT_RATE'] = (early_payments / total_payments).fillna(0)\n",
    "inst_prev_agg['INST_LATE_PAYMENT_RATE'] = (late_payments / total_payments).fillna(0)\n",
    "inst_prev_agg['INST_FULL_PAYMENT_RATE'] = (full_payments / total_payments).fillna(0)\n",
    "\n",
    "# Map to SK_ID_CURR\n",
    "inst_curr_map = inst_pay[['SK_ID_CURR', 'SK_ID_PREV']].drop_duplicates()\n",
    "inst_prev_agg = inst_curr_map.merge(inst_prev_agg, on='SK_ID_PREV', how='left')\n",
    "\n",
    "# Aggregate to customer level\n",
    "inst_final = inst_prev_agg.groupby('SK_ID_CURR').mean().reset_index()\n",
    "inst_final.rename(columns={'SK_ID_PREV': 'INST_SK_ID_PREV_count'}, inplace=True)\n",
    "\n",
    "print(f'âœ… Created {inst_final.shape[1]-1} installments_payments features')\n",
    "print(f'Customers with installment data: {inst_final.shape[0]:,}')\n",
    "\n",
    "display(inst_final.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 7 â€” Merge All Datasets\n",
    "\n",
    "Now we merge all aggregated features back to the main application data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ”§ Merging all datasets...')\n",
    "print(f'Starting with: {app_train.shape}')\n",
    "\n",
    "# Merge bureau\n",
    "df = app_train.merge(bureau_full, on='SK_ID_CURR', how='left')\n",
    "print(f'After bureau: {df.shape}')\n",
    "\n",
    "# Merge previous applications\n",
    "df = df.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
    "print(f'After prev_app: {df.shape}')\n",
    "\n",
    "# Merge POS cash\n",
    "df = df.merge(pos_final, on='SK_ID_CURR', how='left')\n",
    "print(f'After POS_CASH: {df.shape}')\n",
    "\n",
    "# Merge credit card\n",
    "df = df.merge(cc_final, on='SK_ID_CURR', how='left')\n",
    "print(f'After credit_card: {df.shape}')\n",
    "\n",
    "# Merge installments\n",
    "df = df.merge(inst_final, on='SK_ID_CURR', how='left')\n",
    "print(f'After installments: {df.shape}')\n",
    "\n",
    "print(f'\\nâœ… Final merged dataset: {df.shape}')\n",
    "print(f'Total features: {df.shape[1]}')\n",
    "print(f'Total rows: {df.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 8 â€” Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ” Checking merged data quality...')\n",
    "\n",
    "# Missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'feature': missing.index,\n",
    "    'missing_count': missing.values,\n",
    "    'missing_pct': missing_pct.values\n",
    "}).sort_values('missing_pct', ascending=False)\n",
    "\n",
    "high_missing = missing_df[missing_df.missing_pct > 50]\n",
    "print(f'\\nFeatures with >50% missing: {len(high_missing)}')\n",
    "\n",
    "if len(high_missing) > 0:\n",
    "    print('\\nTop 10 features with most missing:')\n",
    "    display(high_missing.head(10))\n",
    "\n",
    "# Data types\n",
    "print(f'\\nData types:')\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify target distribution\n",
    "print('ðŸŽ¯ Target distribution check:')\n",
    "print(df['TARGET'].value_counts())\n",
    "print(f'Default rate: {df[\"TARGET\"].mean()*100:.2f}%')\n",
    "\n",
    "# Verify no duplicate rows\n",
    "print(f'\\nDuplicate rows: {df.duplicated().sum()}')\n",
    "\n",
    "# Memory usage\n",
    "print(f'\\nMemory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##  STEP 9 â€” Save Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('../data/merged', exist_ok=True)\n",
    "\n",
    "# Separate X and y\n",
    "X_merged = df.drop(columns=['TARGET'])\n",
    "y_merged = df['TARGET']\n",
    "\n",
    "# Save to CSV\n",
    "print('ðŸ’¾ Saving merged datasets...')\n",
    "X_merged.to_csv('../data/merged/x_train_merged.csv', index=False)\n",
    "y_merged.to_csv('../data/merged/y_train.csv', index=False, header=True)\n",
    "\n",
    "print(f'\\nâœ… Saved:')\n",
    "print(f'   x_train_merged.csv: {X_merged.shape}')\n",
    "print(f'   y_train.csv: {y_merged.shape}')\n",
    "\n",
    "# Also save full feature list\n",
    "feature_list = pd.DataFrame({'feature': X_merged.columns})\n",
    "feature_list.to_csv('../data/merged/feature_names.txt', index=False, header=False)\n",
    "print(f'   feature_names.txt: {len(X_merged.columns)} features')\n",
    "\n",
    "print('\\nðŸŽ‰ Data integration complete!')\n",
    "print(f'\\nYou now have a merged dataset with {X_merged.shape[1]} features ready for preprocessing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##  STEP 10 â€” Quick Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ“Š FINAL SUMMARY')\n",
    "print('='*70)\n",
    "print(f'Total applications:        {X_merged.shape[0]:,}')\n",
    "print(f'Total features:            {X_merged.shape[1]:,}')\n",
    "print(f'Default rate:              {y_merged.mean()*100:.2f}%')\n",
    "print(f'Features from each source:')\n",
    "print(f'  - Application (base):    ~122')\n",
    "print(f'  - Bureau:                {len([c for c in X_merged.columns if c.startswith(\"BUREAU\")])}')\n",
    "print(f'  - Previous apps:         {len([c for c in X_merged.columns if c.startswith(\"PREV\")])}')\n",
    "print(f'  - POS/Cash:              {len([c for c in X_merged.columns if c.startswith(\"POS\")])}')\n",
    "print(f'  - Credit card:           {len([c for c in X_merged.columns if c.startswith(\"CC\")])}')\n",
    "print(f'  - Installments:          {len([c for c in X_merged.columns if c.startswith(\"INST\")])}')\n",
    "print('='*70)\n",
    "\n",
    "# Create a summary report\n",
    "summary = {\n",
    "    'Total Applications': X_merged.shape[0],\n",
    "    'Total Features': X_merged.shape[1],\n",
    "    'Default Rate (%)': round(y_merged.mean()*100, 2),\n",
    "    'Missing Value %': round(X_merged.isnull().sum().sum() / (X_merged.shape[0] * X_merged.shape[1]) * 100, 2),\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv('../reports/data_merge_summary.csv', index=False)\n",
    "print('\\nâœ… Summary saved to reports/data_merge_summary.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
